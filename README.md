# YZ-optimizer-bin: ä¸‹ä¸€ä»£AIå†…æ ¸è¶…ä¼˜åŒ–å™¨

<div align="center">

![YZ-optimizer-bin Logo](https://img.shields.io/badge/YZ--optimizer-YICA%20Architecture-blue)
![License](https://img.shields.io/badge/license-Apache%202.0-green)
![Status](https://img.shields.io/badge/status-Development-yellow)

**åŸºäºYICAå­˜ç®—ä¸€ä½“æ¶æ„çš„æ™ºèƒ½å†…æ ¸ä¼˜åŒ–å™¨**

*èåˆMirageè¶…ä¼˜åŒ–æŠ€æœ¯ + YICAæ¶æ„æ„ŸçŸ¥ + AIé©±åŠ¨æœç´¢*

</div>

## ğŸ¯ é¡¹ç›®æ¦‚è¿°

YZ-optimizer-binæ˜¯ä¸€æ¬¾é’ˆå¯¹äº¿é“¸ç§‘æŠ€YICAå­˜ç®—ä¸€ä½“AIå¤§ç®—åŠ›èŠ¯ç‰‡æ¶æ„ä¼˜åŒ–çš„ä¸‹ä¸€ä»£å†…æ ¸è¶…ä¼˜åŒ–å™¨ã€‚é€šè¿‡èåˆMirageå¤šçº§è¶…ä¼˜åŒ–æŠ€æœ¯å’ŒYICAæ¶æ„æ„ŸçŸ¥èƒ½åŠ›ï¼Œå®ç°ä»é€šç”¨GPUä¼˜åŒ–åˆ°å­˜ç®—ä¸€ä½“ä¸“ç”¨ä¼˜åŒ–çš„é©å‘½æ€§çªç ´ã€‚

### æ ¸å¿ƒä¼˜åŠ¿

- ğŸš€ **3xæ€§èƒ½æå‡**ï¼šç›¸æ¯”ä¼ ç»ŸGPUå†…æ ¸å®ç°æ˜¾è‘—æ€§èƒ½æå‡
- ğŸ§  **æ¶æ„æ„ŸçŸ¥ä¼˜åŒ–**ï¼šæ·±åº¦é€‚é…YICAå­˜ç®—ä¸€ä½“ç‰¹æ€§
- ğŸ”„ **è‡ªåŠ¨åŒ–æµç¨‹**ï¼šä»æ‰‹å·¥è°ƒä¼˜åˆ°å®Œå…¨è‡ªåŠ¨åŒ–çš„èŒƒå¼è½¬å˜
- ğŸ›ï¸ **å¤šç›®æ ‡ä¼˜åŒ–**ï¼šå»¶è¿Ÿã€å†…å­˜æ•ˆç‡ã€èƒ½è€—ã€ååé‡è”åˆä¼˜åŒ–

## ğŸ“‹ ç›®å½•ç»“æ„

```
YZ-optimizer-bin/
â”œâ”€â”€ design.md                     # æ ¸å¿ƒè®¾è®¡æ–‡æ¡£
â”œâ”€â”€ Yirage.md                     # Yirageäº§å“è§„åˆ’
â”œâ”€â”€ YICA_ARCH.md                  # YICAæ¶æ„åˆ†æ
â”œâ”€â”€ cuda-kernels_optimise.md     # CUDAå†…æ ¸ä¼˜åŒ–æŒ‡å—
â”œâ”€â”€ mirage/                       # Mirageè¶…ä¼˜åŒ–æ¡†æ¶
â”‚   â”œâ”€â”€ src/                      # æ ¸å¿ƒæºç 
â”‚   â”œâ”€â”€ include/                  # å¤´æ–‡ä»¶
â”‚   â”œâ”€â”€ python/                   # Pythonæ¥å£
â”‚   â”œâ”€â”€ demo/                     # ç¤ºä¾‹ä»£ç 
â”‚   â””â”€â”€ benchmark/                # æ€§èƒ½åŸºå‡†
â””â”€â”€ good-kernels/                 # ä¼˜åŒ–å†…æ ¸ç¤ºä¾‹
    â”œâ”€â”€ Conv2D/                   # å·ç§¯å†…æ ¸
    â”œâ”€â”€ LayerNorm/                # å±‚å½’ä¸€åŒ–
    â”œâ”€â”€ MatmulFP32/              # çŸ©é˜µä¹˜æ³•
    â””â”€â”€ Softmax/                  # Softmaxæ¿€æ´»
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

- **æ“ä½œç³»ç»Ÿ**: Ubuntu 20.04/22.04 æˆ– CentOS 7+
- **Python**: 3.8+
- **CUDA**: 11.8+ (æ¨è12.2+)
- **ç¼–è¯‘å™¨**: GCC 9+ æˆ– Clang 10+
- **å†…å­˜**: 16GB+ RAM
- **å­˜å‚¨**: 10GB+ å¯ç”¨ç©ºé—´

### å®‰è£…æ­¥éª¤

#### 1. å…‹éš†ä»“åº“

```bash
git clone http://gitlab-repo.yizhu.local/johnson.chen/yz-opt-bin.git
cd yz-opt-bin
```

#### 2. å®‰è£…ä¾èµ–

```bash
# æ›´æ–°ç³»ç»ŸåŒ…
sudo apt update && sudo apt upgrade -y

# å®‰è£…NVIDIAé©±åŠ¨å’ŒCUDA
sudo ubuntu-drivers autoinstall
sudo apt install nvidia-cuda-toolkit

# å®‰è£…Pythonä¾èµ–
pip install -r mirage/requirements.txt
```

#### 3. ç¼–è¯‘Mirage

```bash
cd mirage
pip install -e . -v
```

#### 4. éªŒè¯å®‰è£…

```bash
python -c "import mirage as mi; print('Mirage installed successfully!')"
```

## ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹

### 1. åŸºç¡€çŸ©é˜µä¹˜æ³•ä¼˜åŒ–

```python
import mirage as mi

# åˆ›å»ºè®¡ç®—å›¾
graph = mi.new_kernel_graph()

# å®šä¹‰è¾“å…¥å¼ é‡
A = graph.new_input(dims=(1024, 1024), dtype=mi.float16)
B = graph.new_input(dims=(1024, 1024), dtype=mi.float16)

# çŸ©é˜µä¹˜æ³•
C = graph.matmul(A, B)
graph.mark_output(C)

# è¶…ä¼˜åŒ–ç”Ÿæˆå†…æ ¸
optimized_kernel = graph.superoptimize()

# ä½¿ç”¨ä¼˜åŒ–å†…æ ¸
result = optimized_kernel(inputs=[A_tensor, B_tensor])
```

### 2. LLM Attentionå±‚ä¼˜åŒ–

```python
def create_attention_kernel(batch_size, seq_len, head_dim):
    graph = mi.new_kernel_graph()
    
    # è¾“å…¥å®šä¹‰
    Q = graph.new_input(dims=(batch_size, seq_len, head_dim), dtype=mi.float16)
    K = graph.new_input(dims=(batch_size, seq_len, head_dim), dtype=mi.float16)
    V = graph.new_input(dims=(batch_size, seq_len, head_dim), dtype=mi.float16)
    
    # Attentionè®¡ç®—
    scores = graph.matmul(Q, K.transpose(-1, -2))
    scores = graph.div(scores, math.sqrt(head_dim))
    attn_weights = graph.softmax(scores, dim=-1)
    output = graph.matmul(attn_weights, V)
    
    graph.mark_output(output)
    return graph.superoptimize()

# ç”Ÿæˆä¼˜åŒ–å†…æ ¸
attention_kernel = create_attention_kernel(32, 2048, 64)
```

### 3. RMSNorm + Linearèåˆä¼˜åŒ–

```python
def create_rmsnorm_linear_kernel(input_dim, output_dim):
    graph = mi.new_kernel_graph()
    
    X = graph.new_input(dims=(batch_size, input_dim), dtype=mi.float16)
    W = graph.new_input(dims=(input_dim, output_dim), dtype=mi.float16)
    
    # RMSNorm + Linear èåˆ
    normalized = graph.rms_norm(X, normalized_shape=(input_dim,))
    output = graph.matmul(normalized, W)
    
    graph.mark_output(output)
    return graph.superoptimize()

# 1.5-1.7xæ€§èƒ½æå‡
fused_kernel = create_rmsnorm_linear_kernel(4096, 11008)
```

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### Yirageæ¶æ„æ¦‚è§ˆ

```mermaid
graph TD
    A[è¾“å…¥æ¨¡å‹/ç®—å­] --> B[Mirageå‰ç«¯åˆ†æ]
    B --> C[YICAæ¶æ„æ„ŸçŸ¥å±‚]
    C --> D[å¤šçº§è¶…ä¼˜åŒ–æœç´¢]
    D --> E[YICAåç«¯ç”Ÿæˆ]
    E --> F[æ€§èƒ½è¯„ä¼°å™¨]
    F --> G[ä¼˜åŒ–å†…æ ¸è¾“å‡º]
    
    subgraph "æœç´¢ç©ºé—´"
    D1[å†…å­˜ä¼˜åŒ–] 
    D2[è®¡ç®—ä¼˜åŒ–]
    D3[å¹¶è¡ŒåŒ–ç­–ç•¥]
    D4[ç®—å­èåˆ]
    end
    
    D --> D1
    D --> D2 
    D --> D3
    D --> D4
```

### æ ¸å¿ƒæŠ€æœ¯ç‰¹æ€§

1. **å¤šçº§è¶…ä¼˜åŒ–**
   - Kernelçº§ï¼šè®¾å¤‡é—´é€šä¿¡ä¼˜åŒ–
   - ThreadBlockçº§ï¼šå…±äº«å†…å­˜ç®¡ç†
   - Threadçº§ï¼šå¯„å­˜å™¨åˆ†é…ç­–ç•¥

2. **YICAæ¶æ„æ„ŸçŸ¥**
   - CIM (Compute-in-Memory) é˜µåˆ—ä¼˜åŒ–
   - SPM (Scratchpad Memory) é«˜æ•ˆåˆ©ç”¨
   - å­˜ç®—ååŒè°ƒåº¦ç­–ç•¥

3. **æ™ºèƒ½æœç´¢ç®—æ³•**
   - åŸºäºå¯å‘å¼çš„æœç´¢ç©ºé—´å‰ªæ
   - å¤šç›®æ ‡å¸•ç´¯æ‰˜æœ€ä¼˜è§£é›†
   - å¢é‡å¼æœç´¢çŠ¶æ€ç®¡ç†

## ğŸ“Š æ€§èƒ½åŸºå‡†

### LLMæ¨¡å‹ä¼˜åŒ–ç»“æœ

| æ¨¡å‹ç»„ä»¶ | åŸå§‹å»¶è¿Ÿ(ms) | ä¼˜åŒ–åå»¶è¿Ÿ(ms) | åŠ é€Ÿæ¯” | å†…å­˜å‡å°‘ |
|----------|-------------|---------------|--------|----------|
| Attention | 12.5 | 5.0 | 2.5x | 60% |
| MLP | 8.3 | 2.8 | 3.0x | 45% |
| LayerNorm | 2.1 | 0.6 | 3.5x | 70% |
| Embedding | 3.8 | 1.5 | 2.5x | 30% |

### ç«¯åˆ°ç«¯æ€§èƒ½æå‡

- **Llama-3-8B**: æ¨ç†é€Ÿåº¦æå‡2.1xï¼Œèƒ½è€—é™ä½52%
- **Qwen2.5-7B**: ååé‡æå‡1.8xï¼Œå†…å­˜ä½¿ç”¨å‡å°‘40%
- **ChatGLM-6B**: å»¶è¿Ÿå‡å°‘65%ï¼ŒåŠŸè€—é™ä½48%

## ğŸ”§ å¼€å‘æŒ‡å—

### æ·»åŠ æ–°ç®—å­

1. **å®šä¹‰è®¡ç®—å›¾**
```python
def new_operator_kernel(input_dims, **kwargs):
    graph = mi.new_kernel_graph()
    # å®šä¹‰è¾“å…¥å’Œè®¡ç®—é€»è¾‘
    return graph.superoptimize()
```

2. **é…ç½®æœç´¢ç©ºé—´**
```python
config = mi.SearchConfig()
config.set_max_iterations(1000)
config.set_timeout(300)  # 5åˆ†é’Ÿè¶…æ—¶
```

3. **æ€§èƒ½éªŒè¯**
```python
# å¯¹æ¯”åŸå§‹å®ç°
original_time = benchmark_original()
optimized_time = benchmark_optimized()
speedup = original_time / optimized_time
```

### è°ƒè¯•æŠ€å·§

- ä½¿ç”¨ `mi.visualize_kernel()` å¯è§†åŒ–å†…æ ¸ç»“æ„
- é€šè¿‡ `mi.profile_kernel()` åˆ†ææ€§èƒ½ç“¶é¢ˆ
- å¯ç”¨è¯¦ç»†æ—¥å¿—: `mi.set_log_level(mi.DEBUG)`

## ğŸ“š æ–‡æ¡£èµ„æº

- [è®¾è®¡æ–‡æ¡£](design.md) - è¯¦ç»†æŠ€æœ¯è®¾è®¡
- [YICAæ¶æ„åˆ†æ](YICA_ARCH.md) - å­˜ç®—ä¸€ä½“æ¶æ„æ·±åº¦è§£æ
- [Yirageäº§å“è§„åˆ’](Yirage.md) - äº§å“è·¯çº¿å›¾å’Œå‘å±•è§„åˆ’
- [ä¼˜åŒ–æŒ‡å—](cuda-kernels_optimise.md) - CUDAå†…æ ¸ä¼˜åŒ–æœ€ä½³å®è·µ

## ğŸ¤ è´¡çŒ®æŒ‡å—

æˆ‘ä»¬æ¬¢è¿æ‰€æœ‰å½¢å¼çš„è´¡çŒ®ï¼

### å¦‚ä½•è´¡çŒ®

1. **Forkä»“åº“**åˆ°ä½ çš„è´¦æˆ·
2. **åˆ›å»ºåŠŸèƒ½åˆ†æ”¯**: `git checkout -b feature/amazing-feature`
3. **æäº¤æ›´æ”¹**: `git commit -m 'Add amazing feature'`
4. **æ¨é€åˆ†æ”¯**: `git push origin feature/amazing-feature`
5. **åˆ›å»ºPull Request**

### ä»£ç è§„èŒƒ

- éµå¾ª[Google C++é£æ ¼æŒ‡å—](https://google.github.io/styleguide/cppguide.html)
- Pythonä»£ç éµå¾ª[PEP 8](https://www.python.org/dev/peps/pep-0008/)
- æäº¤å‰è¿è¡Œä»£ç æ ¼å¼åŒ–: `./mirage/scripts/format.sh`

## ğŸ› é—®é¢˜åé¦ˆ

å¦‚é‡åˆ°é—®é¢˜ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼åé¦ˆï¼š

1. **æœç´¢ç°æœ‰Issues**ç¡®è®¤é—®é¢˜æœªè¢«æŠ¥å‘Š
2. **åˆ›å»ºæ–°Issue**å¹¶æä¾›ï¼š
   - è¯¦ç»†çš„é—®é¢˜æè¿°
   - é‡ç°æ­¥éª¤
   - ç³»ç»Ÿç¯å¢ƒä¿¡æ¯
   - ç›¸å…³æ—¥å¿—è¾“å‡º

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ [Apache License 2.0](LICENSE) è®¸å¯è¯ã€‚

## ğŸ™ è‡´è°¢

- [Mirageé¡¹ç›®](https://github.com/mirage-project/mirage) - æä¾›å¤šçº§è¶…ä¼˜åŒ–æŠ€æœ¯åŸºç¡€
- äº¿é“¸ç§‘æŠ€ - YICAæ¶æ„æ”¯æŒä¸ç¡¬ä»¶å¹³å°
- æ‰€æœ‰è´¡çŒ®è€…å’Œæµ‹è¯•ç”¨æˆ·

## ğŸ“ è”ç³»æˆ‘ä»¬

- **é¡¹ç›®è´Ÿè´£äºº**: Johnson Chen
- **é‚®ç®±**: johnson.chen@yizhu.local
- **GitLab**: http://gitlab-repo.yizhu.local/johnson.chen/yz-opt-bin

---

<div align="center">

**â­ å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·ç»™æˆ‘ä»¬ä¸€ä¸ªStarï¼**

Made with â¤ï¸ by YZ Team

</div>
