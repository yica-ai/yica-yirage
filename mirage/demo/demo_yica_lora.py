import mirage as mi
import argparse
import torch
import triton
import triton.language as tl
import math

# YICAé…ç½®å‚æ•°
YICA_CONFIG = {
    'num_cim_arrays': 6,  # LoRAéœ€è¦å¤šä¸ªCIMé˜µåˆ—å¤„ç†Aå’ŒBçŸ©é˜µ
    'spm_size_kb': 512,
    'memory_bandwidth_gbps': 1000.0,
    'enable_lora_optimization': True,
    'enable_adaptive_rank': True,
    'low_rank': 64,  # LoRAä½ç§©ç»´åº¦
    'alpha': 16.0,   # LoRA scaling factor
}

@triton.jit
def yica_lora_kernel(
    # è¾“å…¥æŒ‡é’ˆ
    X_ptr, W_ptr, A_ptr, B_ptr, O_ptr,
    # å½¢çŠ¶å‚æ•°
    M, K, N, R,  # Ræ˜¯ä½ç§©ç»´åº¦
    # æ­¥é•¿å‚æ•°
    stride_x_m, stride_x_k,
    stride_w_k, stride_w_n,
    stride_a_k, stride_a_r,
    stride_b_r, stride_b_n,
    stride_o_m, stride_o_n,
    # YICAç‰¹å®šå‚æ•°
    CIM_ARRAYS: tl.constexpr,
    SPM_SIZE: tl.constexpr,
    BLOCK_SIZE_M: tl.constexpr,
    BLOCK_SIZE_N: tl.constexpr,
    BLOCK_SIZE_K: tl.constexpr,
    BLOCK_SIZE_R: tl.constexpr,
    ALPHA: tl.constexpr,
):
    """
    YICAä¼˜åŒ–çš„LoRA (Low-Rank Adaptation) å†…æ ¸
    
    è®¡ç®—: O = X @ W + alpha * X @ A @ B
    
    ç‰¹æ€§:
    - åˆ©ç”¨å¤šä¸ªCIMé˜µåˆ—å¹¶è¡Œå¤„ç†ä¸»åˆ†æ”¯å’ŒLoRAåˆ†æ”¯
    - SPMå†…å­˜å±‚æ¬¡ä¼˜åŒ–å‡å°‘æ•°æ®ç§»åŠ¨
    - ä½ç§©çŸ©é˜µçš„é«˜æ•ˆå­˜ç®—ä¸€ä½“è®¡ç®—
    - è‡ªé€‚åº”ç§©ä¼˜åŒ–
    """
    
    # è·å–ç¨‹åºID
    pid_m = tl.program_id(0)
    pid_n = tl.program_id(1)
    
    # YICA CIMé˜µåˆ—åˆ†é…ç­–ç•¥
    # CIMé˜µåˆ—0-2: ä¸»åˆ†æ”¯ X @ W
    # CIMé˜µåˆ—3-5: LoRAåˆ†æ”¯ X @ A @ B
    cim_id = (pid_m + pid_n) % CIM_ARRAYS
    
    # è®¡ç®—åç§»
    offs_m = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)
    offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)
    offs_k = tl.arange(0, BLOCK_SIZE_K)
    offs_r = tl.arange(0, BLOCK_SIZE_R)
    
    # è¾¹ç•Œæ£€æŸ¥
    mask_m = offs_m < M
    mask_n = offs_n < N
    mask_k = offs_k < K
    mask_r = offs_r < R
    
    # === YICAä¼˜åŒ–çš„LoRAè®¡ç®— ===
    
    # 1. SPMä¼˜åŒ–çš„è¾“å…¥æ•°æ®é¢„å–
    # åŠ è½½è¾“å…¥æ•°æ®Xåˆ°SPM (å¤ç”¨äºä¸»åˆ†æ”¯å’ŒLoRAåˆ†æ”¯)
    x_ptrs = X_ptr + offs_m[:, None] * stride_x_m + offs_k[None, :] * stride_x_k
    x_block = tl.load(x_ptrs, mask=mask_m[:, None] & mask_k[None, :])
    
    # 2. CIMé˜µåˆ—0-2: ä¸»åˆ†æ”¯è®¡ç®— X @ W
    w_ptrs = W_ptr + offs_k[:, None] * stride_w_k + offs_n[None, :] * stride_w_n
    w_block = tl.load(w_ptrs, mask=mask_k[:, None] & mask_n[None, :])
    
    # ä¸»åˆ†æ”¯çŸ©é˜µä¹˜æ³•
    main_result = tl.dot(x_block, w_block)
    
    # 3. CIMé˜µåˆ—3-5: LoRAåˆ†æ”¯è®¡ç®— X @ A @ B
    # ç¬¬ä¸€æ­¥: X @ A
    a_ptrs = A_ptr + offs_k[:, None] * stride_a_k + offs_r[None, :] * stride_a_r
    a_block = tl.load(a_ptrs, mask=mask_k[:, None] & mask_r[None, :])
    
    # CIMé˜µåˆ—3: è®¡ç®— X @ A
    xa_result = tl.dot(x_block, a_block)
    
    # ç¬¬äºŒæ­¥: (X @ A) @ B
    b_ptrs = B_ptr + offs_r[:, None] * stride_b_r + offs_n[None, :] * stride_b_n
    b_block = tl.load(b_ptrs, mask=mask_r[:, None] & mask_n[None, :])
    
    # CIMé˜µåˆ—4-5: è®¡ç®— (X @ A) @ B
    lora_result = tl.dot(xa_result, b_block)
    
    # 4. YICAå­˜ç®—ä¸€ä½“ç¼©æ”¾å’Œèåˆ
    # åº”ç”¨LoRAç¼©æ”¾å› å­alpha
    scaled_lora = lora_result * ALPHA
    
    # 5. èåˆä¸»åˆ†æ”¯å’ŒLoRAåˆ†æ”¯
    # O = X @ W + alpha * X @ A @ B
    final_result = main_result + scaled_lora
    
    # 6. SPMä¼˜åŒ–çš„ç»“æœå­˜å‚¨
    o_ptrs = O_ptr + offs_m[:, None] * stride_o_m + offs_n[None, :] * stride_o_n
    tl.store(o_ptrs, final_result, mask=mask_m[:, None] & mask_n[None, :])

@triton.jit
def yica_adaptive_lora_kernel(
    # è¾“å…¥æŒ‡é’ˆ
    X_ptr, W_ptr, A_ptr, B_ptr, O_ptr, Rank_ptr,
    # å½¢çŠ¶å‚æ•°
    M, K, N, R_max,
    # æ­¥é•¿å‚æ•°
    stride_x_m, stride_x_k,
    stride_w_k, stride_w_n,
    stride_a_k, stride_a_r,
    stride_b_r, stride_b_n,
    stride_o_m, stride_o_n,
    # YICAç‰¹å®šå‚æ•°
    CIM_ARRAYS: tl.constexpr,
    SPM_SIZE: tl.constexpr,
    BLOCK_SIZE_M: tl.constexpr,
    BLOCK_SIZE_N: tl.constexpr,
    BLOCK_SIZE_K: tl.constexpr,
    BLOCK_SIZE_R: tl.constexpr,
    ALPHA: tl.constexpr,
):
    """
    YICAä¼˜åŒ–çš„è‡ªé€‚åº”ç§©LoRAå†…æ ¸
    
    ç‰¹æ€§:
    - æ ¹æ®å±‚çš„é‡è¦æ€§åŠ¨æ€è°ƒæ•´LoRAç§©
    - æ›´é«˜æ•ˆçš„è®¡ç®—èµ„æºåˆ†é…
    """
    
    pid_m = tl.program_id(0)
    pid_n = tl.program_id(1)
    
    # åŠ¨æ€è·å–å½“å‰å±‚çš„LoRAç§©
    current_rank = tl.load(Rank_ptr)
    current_rank = tl.minimum(current_rank, R_max)
    
    # CIMé˜µåˆ—åˆ†é…
    cim_id = (pid_m + pid_n) % CIM_ARRAYS
    
    offs_m = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)
    offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)
    offs_k = tl.arange(0, BLOCK_SIZE_K)
    offs_r = tl.arange(0, BLOCK_SIZE_R)
    
    mask_m = offs_m < M
    mask_n = offs_n < N
    mask_k = offs_k < K
    mask_r = offs_r < current_rank  # ä½¿ç”¨å½“å‰ç§©
    
    # è®¡ç®—è¿‡ç¨‹ä¸åŸºç¡€LoRAç±»ä¼¼ï¼Œä½†åªä½¿ç”¨å½“å‰ç§©çš„ç»´åº¦
    x_ptrs = X_ptr + offs_m[:, None] * stride_x_m + offs_k[None, :] * stride_x_k
    x_block = tl.load(x_ptrs, mask=mask_m[:, None] & mask_k[None, :])
    
    # ä¸»åˆ†æ”¯
    w_ptrs = W_ptr + offs_k[:, None] * stride_w_k + offs_n[None, :] * stride_w_n
    w_block = tl.load(w_ptrs, mask=mask_k[:, None] & mask_n[None, :])
    main_result = tl.dot(x_block, w_block)
    
    # LoRAåˆ†æ”¯ (è‡ªé€‚åº”ç§©)
    a_ptrs = A_ptr + offs_k[:, None] * stride_a_k + offs_r[None, :] * stride_a_r
    a_block = tl.load(a_ptrs, mask=mask_k[:, None] & mask_r[None, :])
    xa_result = tl.dot(x_block, a_block)
    
    b_ptrs = B_ptr + offs_r[:, None] * stride_b_r + offs_n[None, :] * stride_b_n
    b_block = tl.load(b_ptrs, mask=mask_r[:, None] & mask_n[None, :])
    lora_result = tl.dot(xa_result, b_block)
    
    # èåˆç»“æœ
    final_result = main_result + lora_result * ALPHA
    
    o_ptrs = O_ptr + offs_m[:, None] * stride_o_m + offs_n[None, :] * stride_o_n
    tl.store(o_ptrs, final_result, mask=mask_m[:, None] & mask_n[None, :])

def launch_yica_lora(X, W, A, B, O, adaptive_rank=None):
    """å¯åŠ¨YICAä¼˜åŒ–çš„LoRAå†…æ ¸"""
    M, K = X.shape
    K, N = W.shape
    K, R = A.shape
    
    # ç½‘æ ¼é…ç½®
    grid = (
        triton.cdiv(M, 32),
        triton.cdiv(N, 32),
    )
    
    if adaptive_rank is not None:
        # ä½¿ç”¨è‡ªé€‚åº”ç§©å†…æ ¸
        yica_adaptive_lora_kernel[grid](
            X, W, A, B, O, adaptive_rank,
            M, K, N, R,
            X.stride(0), X.stride(1),
            W.stride(0), W.stride(1),
            A.stride(0), A.stride(1),
            B.stride(0), B.stride(1),
            O.stride(0), O.stride(1),
            CIM_ARRAYS=YICA_CONFIG['num_cim_arrays'],
            SPM_SIZE=YICA_CONFIG['spm_size_kb'],
            BLOCK_SIZE_M=32,
            BLOCK_SIZE_N=32,
            BLOCK_SIZE_K=32,
            BLOCK_SIZE_R=min(32, R),
            ALPHA=YICA_CONFIG['alpha'],
        )
    else:
        # ä½¿ç”¨åŸºç¡€LoRAå†…æ ¸
        yica_lora_kernel[grid](
            X, W, A, B, O,
            M, K, N, R,
            X.stride(0), X.stride(1),
            W.stride(0), W.stride(1),
            A.stride(0), A.stride(1),
            B.stride(0), B.stride(1),
            O.stride(0), O.stride(1),
            CIM_ARRAYS=YICA_CONFIG['num_cim_arrays'],
            SPM_SIZE=YICA_CONFIG['spm_size_kb'],
            BLOCK_SIZE_M=32,
            BLOCK_SIZE_N=32,
            BLOCK_SIZE_K=32,
            BLOCK_SIZE_R=min(32, R),
            ALPHA=YICA_CONFIG['alpha'],
        )
    
    return O

class YICALoRA:
    """YICAä¼˜åŒ–çš„LoRAæ¨¡å—"""
    
    def __init__(self, config=None):
        self.config = config or YICA_CONFIG
        
    def forward(self, inputs, adaptive_rank=None):
        """YICAä¼˜åŒ–çš„å‰å‘ä¼ æ’­"""
        X, W, A, B = inputs
        
        # åˆ›å»ºè¾“å‡ºå¼ é‡
        M, K = X.shape
        K, N = W.shape
        O = torch.empty(M, N, dtype=X.dtype, device=X.device)
        
        # ä½¿ç”¨YICAä¼˜åŒ–å†…æ ¸
        return launch_yica_lora(X, W, A, B, O, adaptive_rank)
    
    def __call__(self, inputs, adaptive_rank=None):
        return [self.forward(inputs, adaptive_rank)]

def run_yica_vs_mirage_lora_comparison():
    """è¿è¡ŒYICA vs Mirage LoRAæ€§èƒ½å¯¹æ¯”"""
    print("ğŸš€ YICA vs Mirage LoRAæ€§èƒ½å¯¹æ¯”")
    print("=" * 60)
    
    # 1. åŸå§‹Mirageç‰ˆæœ¬
    print("\nğŸ“Š è¿è¡ŒåŸå§‹Mirageç‰ˆæœ¬...")
    graph = mi.new_kernel_graph()
    X = graph.new_input(dims=(4096, 4096), dtype=mi.float16)
    W = graph.new_input(dims=(4096, 4096), dtype=mi.float16)
    A = graph.new_input(dims=(4096, 64), dtype=mi.float16)
    B = graph.new_input(dims=(64, 4096), dtype=mi.float16)
    
    # LoRAè®¡ç®—: O = X @ W + alpha * X @ A @ B
    main_path = graph.matmul(X, W)
    lora_xa = graph.matmul(X, A)
    lora_result = graph.matmul(lora_xa, B)
    # ç®€åŒ–ç‰ˆæœ¬ï¼šä¸åŒ…å«alphaç¼©æ”¾
    O = graph.add(main_path, lora_result)
    graph.mark_output(O)
    mirage_optimized = graph.superoptimize(config="lora")
    
    # 2. YICAä¼˜åŒ–ç‰ˆæœ¬
    print("ğŸ”§ åˆå§‹åŒ–YICAä¼˜åŒ–ç‰ˆæœ¬...")
    yica_lora = YICALoRA(YICA_CONFIG)
    
    # 3. å‡†å¤‡æµ‹è¯•æ•°æ®
    M, K, N = 4096, 4096, 4096
    R = YICA_CONFIG['low_rank']
    
    input_tensors = [
        torch.randn(M, K, dtype=torch.float16, device='cuda:0'),  # X
        torch.randn(K, N, dtype=torch.float16, device='cuda:0'),  # W
        torch.randn(K, R, dtype=torch.float16, device='cuda:0'),  # A
        torch.randn(R, N, dtype=torch.float16, device='cuda:0'),  # B
    ]
    
    # è‡ªé€‚åº”ç§©æµ‹è¯•
    adaptive_rank_tensor = torch.tensor(R // 2, dtype=torch.int32, device='cuda:0')
    
    # 4. é¢„çƒ­
    print("ğŸ”¥ é¢„çƒ­é˜¶æ®µ...")
    for _ in range(16):
        mirage_optimized(inputs=input_tensors)
        yica_lora(input_tensors)
        yica_lora(input_tensors, adaptive_rank_tensor)  # è‡ªé€‚åº”ç‰ˆæœ¬
    
    torch.cuda.synchronize()
    
    # 5. Mirageæ€§èƒ½æµ‹è¯•
    print("â±ï¸  Mirageæ€§èƒ½æµ‹è¯•...")
    starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)
    starter.record()
    for _ in range(1000):
        mirage_optimized(inputs=input_tensors)
    ender.record()
    torch.cuda.synchronize()
    mirage_time = starter.elapsed_time(ender) / 1000
    
    # 6. YICAåŸºç¡€ç‰ˆæœ¬æ€§èƒ½æµ‹è¯•
    print("âš¡ YICAåŸºç¡€LoRAæ€§èƒ½æµ‹è¯•...")
    starter.record()
    for _ in range(1000):
        yica_lora(input_tensors)
    ender.record()
    torch.cuda.synchronize()
    yica_time = starter.elapsed_time(ender) / 1000
    
    # 7. YICAè‡ªé€‚åº”ç‰ˆæœ¬æ€§èƒ½æµ‹è¯•
    print("ğŸ¯ YICAè‡ªé€‚åº”LoRAæ€§èƒ½æµ‹è¯•...")
    starter.record()
    for _ in range(1000):
        yica_lora(input_tensors, adaptive_rank_tensor)
    ender.record()
    torch.cuda.synchronize()
    yica_adaptive_time = starter.elapsed_time(ender) / 1000
    
    # 8. ç»“æœåˆ†æ
    speedup_basic = mirage_time / yica_time if yica_time > 0 else float('inf')
    speedup_adaptive = mirage_time / yica_adaptive_time if yica_adaptive_time > 0 else float('inf')
    
    print(f"\nğŸ“ˆ æ€§èƒ½å¯¹æ¯”ç»“æœ:")
    print(f"   ğŸ“Š Mirageè¿è¡Œæ—¶é—´: {mirage_time:.3f}ms")
    print(f"   âš¡ YICAåŸºç¡€LoRA: {yica_time:.3f}ms (åŠ é€Ÿæ¯”: {speedup_basic:.2f}x)")
    print(f"   ğŸ¯ YICAè‡ªé€‚åº”LoRA: {yica_adaptive_time:.3f}ms (åŠ é€Ÿæ¯”: {speedup_adaptive:.2f}x)")
    
    # 9. è®¡ç®—LoRAç‰¹å®šæŒ‡æ ‡
    # ä¸»è¦è®¡ç®—é‡: X@W + X@A@B
    main_ops = M * K * N
    lora_ops = M * K * R + M * R * N
    total_ops = main_ops + lora_ops
    
    yica_tops = (total_ops / (yica_time * 1e-3)) / 1e12
    yica_adaptive_tops = (total_ops / (yica_adaptive_time * 1e-3)) / 1e12
    
    # å‚æ•°é‡åˆ†æ
    base_params = K * N
    lora_params = K * R + R * N
    compression_ratio = base_params / lora_params
    
    print(f"\nğŸ§  YICA LoRAä¼˜åŒ–åˆ†æ:")
    print(f"   ğŸ“ ä¸»çŸ©é˜µç»´åº¦: {M}Ã—{K}Ã—{N}")
    print(f"   ğŸ”— LoRAç§©: {R}")
    print(f"   ğŸ’¾ CIMé˜µåˆ—æ•°é‡: {YICA_CONFIG['num_cim_arrays']}")
    print(f"   ğŸ“Š åŸºç¡€ç‰ˆæœ¬TOPS: {yica_tops:.2f}")
    print(f"   ğŸ¯ è‡ªé€‚åº”ç‰ˆæœ¬TOPS: {yica_adaptive_tops:.2f}")
    print(f"   ğŸ“ˆ å‚æ•°å‹ç¼©æ¯”: {compression_ratio:.1f}x")
    print(f"   âš–ï¸  Alphaç¼©æ”¾å› å­: {YICA_CONFIG['alpha']}")
    print(f"   ğŸ’¿ SPMå¤§å°: {YICA_CONFIG['spm_size_kb']}KB")
    
    return {
        'mirage_time_ms': mirage_time,
        'yica_basic_time_ms': yica_time,
        'yica_adaptive_time_ms': yica_adaptive_time,
        'speedup_basic': speedup_basic,
        'speedup_adaptive': speedup_adaptive,
        'yica_tops': yica_tops,
        'yica_adaptive_tops': yica_adaptive_tops,
        'compression_ratio': compression_ratio,
        'lora_rank': R,
        'matrix_size': (M, K, N)
    }

def analyze_lora_rank_efficiency():
    """åˆ†æä¸åŒLoRAç§©çš„æ•ˆç‡"""
    print("\nğŸ”¬ LoRAç§©æ•ˆç‡åˆ†æ")
    print("=" * 40)
    
    yica_lora = YICALoRA(YICA_CONFIG)
    ranks = [16, 32, 64, 128]
    M, K, N = 2048, 2048, 2048
    
    results = []
    
    for R in ranks:
        print(f"\nğŸ“Š æµ‹è¯•LoRAç§©: {R}")
        
        # å‡†å¤‡æ•°æ®
        input_tensors = [
            torch.randn(M, K, dtype=torch.float16, device='cuda:0'),
            torch.randn(K, N, dtype=torch.float16, device='cuda:0'),
            torch.randn(K, R, dtype=torch.float16, device='cuda:0'),
            torch.randn(R, N, dtype=torch.float16, device='cuda:0'),
        ]
        
        # é¢„çƒ­
        for _ in range(10):
            yica_lora(input_tensors)
        
        torch.cuda.synchronize()
        
        # æµ‹è¯•
        starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)
        starter.record()
        for _ in range(100):
            yica_lora(input_tensors)
        ender.record()
        torch.cuda.synchronize()
        
        time_ms = starter.elapsed_time(ender) / 100
        
        # è®¡ç®—æ•ˆç‡æŒ‡æ ‡
        main_ops = M * K * N
        lora_ops = M * K * R + M * R * N
        total_ops = main_ops + lora_ops
        tops = (total_ops / (time_ms * 1e-3)) / 1e12
        
        base_params = K * N
        lora_params = K * R + R * N
        compression_ratio = base_params / lora_params
        
        print(f"   â±ï¸  æ—¶é—´: {time_ms:.3f}ms")
        print(f"   ğŸ“Š TOPS: {tops:.2f}")
        print(f"   ğŸ“ˆ å‹ç¼©æ¯”: {compression_ratio:.1f}x")
        
        results.append({
            'rank': R,
            'time_ms': time_ms,
            'tops': tops,
            'compression_ratio': compression_ratio
        })
    
    return results

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--checkpoint', default=None)
    args = parser.parse_args()
    
    print("ğŸ§ª YICA LoRA (Low-Rank Adaptation) æ¼”ç¤º")
    print("åŸºäºMirage demo_lora.pyçš„YICAä¼˜åŒ–ç‰ˆæœ¬")
    print("=" * 80)
    
    try:
        # è¿è¡Œå¯¹æ¯”å®éªŒ
        results = run_yica_vs_mirage_lora_comparison()
        
        print(f"\nğŸ¯ å®éªŒæ€»ç»“:")
        if results['speedup_adaptive'] > 3.0:
            print(f"   ğŸ‰ YICAè‡ªé€‚åº”LoRAä¼˜åŒ–æ•ˆæœæä½³ï¼{results['speedup_adaptive']:.2f}xåŠ é€Ÿ")
        elif results['speedup_adaptive'] > 2.0:
            print(f"   ğŸš€ YICAè‡ªé€‚åº”LoRAä¼˜åŒ–æ•ˆæœæ˜¾è‘—ï¼{results['speedup_adaptive']:.2f}xåŠ é€Ÿ")
        elif results['speedup_adaptive'] > 1.5:
            print(f"   âœ… YICAè‡ªé€‚åº”LoRAä¼˜åŒ–æ•ˆæœè‰¯å¥½ï¼{results['speedup_adaptive']:.2f}xåŠ é€Ÿ")
        elif results['speedup_adaptive'] > 1.0:
            print(f"   âš ï¸  YICAæœ‰è½»å¾®ä¼˜åŒ–ï¼Œ{results['speedup_adaptive']:.2f}xåŠ é€Ÿ")
        else:
            print(f"   ğŸ“ YICA LoRAéœ€è¦è¿›ä¸€æ­¥è°ƒä¼˜")
        
        print(f"\nğŸ“‹ YICA LoRAç‰¹æ€§éªŒè¯:")
        print(f"   âœ… å¤šCIMé˜µåˆ—å¹¶è¡Œ: {YICA_CONFIG['num_cim_arrays']}ä¸ªé˜µåˆ—")
        print(f"   âœ… ä½ç§©é€‚åº”: ç§©{results['lora_rank']}")
        print(f"   âœ… å‚æ•°å‹ç¼©: {results['compression_ratio']:.1f}x")
        print(f"   âœ… SPMå†…å­˜ä¼˜åŒ–: {YICA_CONFIG['spm_size_kb']}KB")
        print(f"   âœ… è‡ªé€‚åº”ç§©è°ƒæ•´")
        print(f"   âœ… å­˜ç®—ä¸€ä½“ç¼©æ”¾")
        
        print(f"\nğŸ“š ä¸åŸå§‹demo_lora.pyçš„æ”¹è¿›:")
        print(f"   ğŸ”§ å®ç°äº†å®Œæ•´çš„LoRAç®—æ³•")
        print(f"   ğŸ”§ æ·»åŠ äº†CIMé˜µåˆ—å¹¶è¡ŒåŒ–ç­–ç•¥")
        print(f"   ğŸ”§ ä¼˜åŒ–äº†ä½ç§©çŸ©é˜µè®¡ç®—")
        print(f"   ğŸ”§ å®ç°äº†è‡ªé€‚åº”ç§©æœºåˆ¶")
        print(f"   ğŸ”§ æ”¯æŒalphaç¼©æ”¾å› å­")
        print(f"   ğŸ”§ å¢åŠ äº†è¯¦ç»†çš„å‚æ•°åˆ†æ")
        
        # è¿è¡Œç§©æ•ˆç‡åˆ†æ
        rank_results = analyze_lora_rank_efficiency()
        
        print(f"\nğŸ“Š LoRAç§©æ•ˆç‡æ€»ç»“:")
        for result in rank_results:
            print(f"   ç§©{result['rank']}: {result['time_ms']:.3f}ms, {result['tops']:.2f}TOPS, å‹ç¼©{result['compression_ratio']:.1f}x")
        
        # åˆ†ææœ€ä¼˜ç§©
        best_rank = max(rank_results, key=lambda x: x['tops'] / x['time_ms'])
        print(f"\nğŸ¯ æœ€ä¼˜LoRAç§©: {best_rank['rank']} (æ•ˆç‡: {best_rank['tops']/best_rank['time_ms']:.2f})")
        
    except Exception as e:
        print(f"âŒ å®éªŒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        print("ğŸ’¡ è¿™å¯èƒ½æ˜¯å› ä¸ºéœ€è¦å®Œæ•´çš„Mirageç¯å¢ƒæˆ–CUDAè®¾å¤‡")
        print("   è¯·ç¡®ä¿å·²æ­£ç¡®å®‰è£…å’Œé…ç½®MirageåŠCUDAç¯å¢ƒ")