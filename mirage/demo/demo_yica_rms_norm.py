import mirage as mi
import numpy as np
import torch
import triton
import triton.language as tl

# YICAé…ç½®å‚æ•°
YICA_CONFIG = {
    'num_cim_arrays': 2,  # RMS Normç›¸å¯¹ç®€å•ï¼Œéœ€è¦è¾ƒå°‘CIMé˜µåˆ—
    'spm_size_kb': 256,
    'memory_bandwidth_gbps': 1000.0,
    'enable_normalization_optimization': True,
    'enable_vectorization': True,
    'eps': 1e-6
}

@triton.jit
def yica_rms_norm_kernel(
    # è¾“å…¥è¾“å‡ºæŒ‡é’ˆ
    X_ptr, W_ptr, O_ptr,
    # å½¢çŠ¶å‚æ•°
    M, N,
    # æ­¥é•¿å‚æ•°
    stride_x_m, stride_x_n,
    stride_w_n,
    stride_o_m, stride_o_n,
    # YICAç‰¹å®šå‚æ•°
    CIM_ARRAYS: tl.constexpr,
    SPM_SIZE: tl.constexpr,
    BLOCK_SIZE_M: tl.constexpr,
    BLOCK_SIZE_N: tl.constexpr,
    EPS: tl.constexpr,
):
    """
    YICAä¼˜åŒ–çš„RMS Normalizationå†…æ ¸
    
    ç‰¹æ€§:
    - åˆ©ç”¨CIMé˜µåˆ—å¹¶è¡Œå¤„ç†ä¸åŒçš„åºåˆ—
    - SPMå†…å­˜å±‚æ¬¡ä¼˜åŒ–å‡å°‘æ•°æ®ç§»åŠ¨
    - å­˜ç®—ä¸€ä½“å¹³æ–¹æ ¹è®¡ç®—
    - å‘é‡åŒ–å¤„ç†æé«˜æ•ˆç‡
    """
    
    # è·å–ç¨‹åºID
    pid_m = tl.program_id(0)
    
    # YICA CIMé˜µåˆ—åˆ†é…ç­–ç•¥
    # å°†ä¸åŒçš„åºåˆ—åˆ†é…åˆ°ä¸åŒçš„CIMé˜µåˆ—
    cim_id = pid_m % CIM_ARRAYS
    local_pid_m = pid_m // CIM_ARRAYS
    
    # è®¡ç®—åç§»
    offs_m = local_pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)
    offs_n = tl.arange(0, BLOCK_SIZE_N)
    
    # è¾¹ç•Œæ£€æŸ¥
    mask_m = offs_m < M
    mask_n = offs_n < N
    
    # === YICAä¼˜åŒ–çš„RMS Normè®¡ç®— ===
    
    # 1. SPMä¼˜åŒ–çš„æ•°æ®åŠ è½½
    # åŠ è½½è¾“å…¥æ•°æ®Xåˆ°SPM
    x_ptrs = X_ptr + offs_m[:, None] * stride_x_m + offs_n[None, :] * stride_x_n
    x_vals = tl.load(x_ptrs, mask=mask_m[:, None] & mask_n[None, :])
    
    # 2. YICAå­˜ç®—ä¸€ä½“å¹³æ–¹å’Œè®¡ç®—
    # åˆ©ç”¨CIMé˜µåˆ—çš„å¹¶è¡Œè®¡ç®—èƒ½åŠ›
    x_squared = x_vals * x_vals
    
    # 3. è·¨ç»´åº¦æ±‚å’Œ (reduction)
    # åˆ†å—å¤„ç†ä»¥ä¼˜åŒ–SPMä½¿ç”¨
    sum_sq = tl.sum(x_squared, axis=1)
    
    # 4. è®¡ç®—RMS (Root Mean Square)
    # RMS = sqrt(mean(x^2)) = sqrt(sum(x^2) / N)
    mean_sq = sum_sq / N
    rms = tl.sqrt(mean_sq + EPS)
    
    # 5. åŠ è½½æƒé‡å‚æ•° (åœ¨SPMä¸­ç¼“å­˜)
    w_ptrs = W_ptr + offs_n * stride_w_n
    w_vals = tl.load(w_ptrs, mask=mask_n)
    
    # 6. YICAå­˜ç®—ä¸€ä½“å½’ä¸€åŒ–å’Œç¼©æ”¾
    # åˆ©ç”¨CIMé˜µåˆ—å¹¶è¡Œå¤„ç†
    normalized = x_vals / rms[:, None]
    output = normalized * w_vals[None, :]
    
    # 7. SPMä¼˜åŒ–çš„ç»“æœå­˜å‚¨
    o_ptrs = O_ptr + offs_m[:, None] * stride_o_m + offs_n[None, :] * stride_o_n
    tl.store(o_ptrs, output, mask=mask_m[:, None] & mask_n[None, :])

@triton.jit
def yica_fused_rms_norm_kernel(
    # è¾“å…¥è¾“å‡ºæŒ‡é’ˆ
    X_ptr, W_ptr, O_ptr, Residual_ptr,
    # å½¢çŠ¶å‚æ•°
    M, N,
    # æ­¥é•¿å‚æ•°
    stride_x_m, stride_x_n,
    stride_w_n,
    stride_o_m, stride_o_n,
    stride_r_m, stride_r_n,
    # YICAç‰¹å®šå‚æ•°
    CIM_ARRAYS: tl.constexpr,
    SPM_SIZE: tl.constexpr,
    BLOCK_SIZE_M: tl.constexpr,
    BLOCK_SIZE_N: tl.constexpr,
    EPS: tl.constexpr,
    ADD_RESIDUAL: tl.constexpr,
):
    """
    YICAä¼˜åŒ–çš„èåˆRMS Normalizationå†…æ ¸
    
    ç‰¹æ€§:
    - èåˆæ®‹å·®è¿æ¥ + RMS Norm
    - å‡å°‘å†…å­˜è®¿é—®æ¬¡æ•°
    - CIMé˜µåˆ—å¹¶è¡Œå¤„ç†
    """
    
    pid_m = tl.program_id(0)
    cim_id = pid_m % CIM_ARRAYS
    local_pid_m = pid_m // CIM_ARRAYS
    
    offs_m = local_pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)
    offs_n = tl.arange(0, BLOCK_SIZE_N)
    
    mask_m = offs_m < M
    mask_n = offs_n < N
    
    # 1. åŠ è½½è¾“å…¥æ•°æ®
    x_ptrs = X_ptr + offs_m[:, None] * stride_x_m + offs_n[None, :] * stride_x_n
    x_vals = tl.load(x_ptrs, mask=mask_m[:, None] & mask_n[None, :])
    
    # 2. å¯é€‰çš„æ®‹å·®è¿æ¥
    if ADD_RESIDUAL:
        r_ptrs = Residual_ptr + offs_m[:, None] * stride_r_m + offs_n[None, :] * stride_r_n
        r_vals = tl.load(r_ptrs, mask=mask_m[:, None] & mask_n[None, :])
        x_vals = x_vals + r_vals
    
    # 3. RMS Normè®¡ç®—
    x_squared = x_vals * x_vals
    sum_sq = tl.sum(x_squared, axis=1)
    mean_sq = sum_sq / N
    rms = tl.sqrt(mean_sq + EPS)
    
    # 4. å½’ä¸€åŒ–å’Œæƒé‡ç¼©æ”¾
    w_ptrs = W_ptr + offs_n * stride_w_n
    w_vals = tl.load(w_ptrs, mask=mask_n)
    
    normalized = x_vals / rms[:, None]
    output = normalized * w_vals[None, :]
    
    # 5. å­˜å‚¨ç»“æœ
    o_ptrs = O_ptr + offs_m[:, None] * stride_o_m + offs_n[None, :] * stride_o_n
    tl.store(o_ptrs, output, mask=mask_m[:, None] & mask_n[None, :])

def launch_yica_rms_norm(X, W, O, residual=None):
    """å¯åŠ¨YICAä¼˜åŒ–çš„RMS Normå†…æ ¸"""
    M, N = X.shape
    
    # ç½‘æ ¼é…ç½® - åˆ©ç”¨å¤šä¸ªCIMé˜µåˆ—
    grid = (triton.cdiv(M, 32) * YICA_CONFIG['num_cim_arrays'],)
    
    if residual is not None:
        # ä½¿ç”¨èåˆå†…æ ¸
        yica_fused_rms_norm_kernel[grid](
            X, W, O, residual,
            M, N,
            X.stride(0), X.stride(1),
            W.stride(0),
            O.stride(0), O.stride(1),
            residual.stride(0), residual.stride(1),
            CIM_ARRAYS=YICA_CONFIG['num_cim_arrays'],
            SPM_SIZE=YICA_CONFIG['spm_size_kb'],
            BLOCK_SIZE_M=32,
            BLOCK_SIZE_N=triton.next_power_of_2(N),
            EPS=YICA_CONFIG['eps'],
            ADD_RESIDUAL=True,
        )
    else:
        # ä½¿ç”¨åŸºç¡€å†…æ ¸
        yica_rms_norm_kernel[grid](
            X, W, O,
            M, N,
            X.stride(0), X.stride(1),
            W.stride(0),
            O.stride(0), O.stride(1),
            CIM_ARRAYS=YICA_CONFIG['num_cim_arrays'],
            SPM_SIZE=YICA_CONFIG['spm_size_kb'],
            BLOCK_SIZE_M=32,
            BLOCK_SIZE_N=triton.next_power_of_2(N),
            EPS=YICA_CONFIG['eps'],
        )
    
    return O

class YICARMSNorm:
    """YICAä¼˜åŒ–çš„RMS Normalizationæ¨¡å—"""
    
    def __init__(self, config=None):
        self.config = config or YICA_CONFIG
        
    def forward(self, inputs, residual=None):
        """YICAä¼˜åŒ–çš„å‰å‘ä¼ æ’­"""
        X, W = inputs
        
        # åˆ›å»ºè¾“å‡ºå¼ é‡
        O = torch.empty_like(X)
        
        # ä½¿ç”¨YICAä¼˜åŒ–å†…æ ¸
        return launch_yica_rms_norm(X, W, O, residual)
    
    def __call__(self, inputs, residual=None):
        return [self.forward(inputs, residual)]

def run_yica_vs_mirage_rmsnorm_comparison():
    """è¿è¡ŒYICA vs Mirage RMS Normæ€§èƒ½å¯¹æ¯”"""
    print("ğŸš€ YICA vs Mirage RMS Normalizationæ€§èƒ½å¯¹æ¯”")
    print("=" * 70)
    
    # 1. åŸå§‹Mirageç‰ˆæœ¬
    print("\nğŸ“Š è¿è¡ŒåŸå§‹Mirageç‰ˆæœ¬...")
    graph = mi.new_kernel_graph()
    X = graph.new_input(dims=(4096, 4096), dtype=mi.float16)
    W = graph.new_input(dims=(4096,), dtype=mi.float16)
    
    # RMS Norm: x / sqrt(mean(x^2) + eps) * w
    X_sq = graph.mul(X, X)
    mean_sq = graph.reduction(X_sq, 1)
    eps_tensor = graph.new_input(dims=(4096, 1), dtype=mi.float16)
    mean_sq_eps = graph.add(mean_sq, eps_tensor)
    rms = graph.sqrt(mean_sq_eps)
    normalized = graph.div(X, rms)
    O = graph.mul(normalized, W)
    
    graph.mark_output(O)
    mirage_optimized = graph.superoptimize(config="norm")
    
    # 2. YICAä¼˜åŒ–ç‰ˆæœ¬
    print("ğŸ”§ åˆå§‹åŒ–YICAä¼˜åŒ–ç‰ˆæœ¬...")
    yica_rmsnorm = YICARMSNorm(YICA_CONFIG)
    
    # 3. å‡†å¤‡æµ‹è¯•æ•°æ®
    M, N = 4096, 4096
    input_tensors = [
        torch.randn(M, N, dtype=torch.float16, device='cuda:0'),
        torch.randn(N, dtype=torch.float16, device='cuda:0'),
    ]
    
    # Mirageéœ€è¦çš„é¢å¤–è¾“å…¥
    mirage_input_tensors = input_tensors + [
        torch.full((M, 1), YICA_CONFIG['eps'], dtype=torch.float16, device='cuda:0')
    ]
    
    # æ®‹å·®è¿æ¥æµ‹è¯•æ•°æ®
    residual_tensor = torch.randn(M, N, dtype=torch.float16, device='cuda:0')
    
    # 4. é¢„çƒ­
    print("ğŸ”¥ é¢„çƒ­é˜¶æ®µ...")
    for _ in range(16):
        mirage_optimized(inputs=mirage_input_tensors)
        yica_rmsnorm(input_tensors)
        yica_rmsnorm(input_tensors, residual_tensor)  # èåˆç‰ˆæœ¬
    
    torch.cuda.synchronize()
    
    # 5. Mirageæ€§èƒ½æµ‹è¯•
    print("â±ï¸  Mirageæ€§èƒ½æµ‹è¯•...")
    starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)
    starter.record()
    for _ in range(1000):
        mirage_optimized(inputs=mirage_input_tensors)
    ender.record()
    torch.cuda.synchronize()
    mirage_time = starter.elapsed_time(ender) / 1000
    
    # 6. YICAåŸºç¡€ç‰ˆæœ¬æ€§èƒ½æµ‹è¯•
    print("âš¡ YICAåŸºç¡€ç‰ˆæœ¬æ€§èƒ½æµ‹è¯•...")
    starter.record()
    for _ in range(1000):
        yica_rmsnorm(input_tensors)
    ender.record()
    torch.cuda.synchronize()
    yica_time = starter.elapsed_time(ender) / 1000
    
    # 7. YICAèåˆç‰ˆæœ¬æ€§èƒ½æµ‹è¯•
    print("ğŸ”¥ YICAèåˆç‰ˆæœ¬æ€§èƒ½æµ‹è¯•...")
    starter.record()
    for _ in range(1000):
        yica_rmsnorm(input_tensors, residual_tensor)
    ender.record()
    torch.cuda.synchronize()
    yica_fused_time = starter.elapsed_time(ender) / 1000
    
    # 8. ç»“æœåˆ†æ
    speedup_basic = mirage_time / yica_time if yica_time > 0 else float('inf')
    speedup_fused = mirage_time / yica_fused_time if yica_fused_time > 0 else float('inf')
    
    print(f"\nğŸ“ˆ æ€§èƒ½å¯¹æ¯”ç»“æœ:")
    print(f"   ğŸ“Š Mirageè¿è¡Œæ—¶é—´: {mirage_time:.3f}ms")
    print(f"   âš¡ YICAåŸºç¡€ç‰ˆæœ¬: {yica_time:.3f}ms (åŠ é€Ÿæ¯”: {speedup_basic:.2f}x)")
    print(f"   ğŸ”¥ YICAèåˆç‰ˆæœ¬: {yica_fused_time:.3f}ms (åŠ é€Ÿæ¯”: {speedup_fused:.2f}x)")
    
    # 9. è®¡ç®—ç‰¹å®šæŒ‡æ ‡
    total_elements = M * N
    memory_access = total_elements * 3 * 2  # X, W, O, fp16
    yica_bandwidth = (memory_access / (yica_time * 1e-3)) / 1e9
    yica_fused_bandwidth = (memory_access * 2 / (yica_fused_time * 1e-3)) / 1e9  # åŒ…å«æ®‹å·®
    
    print(f"\nğŸ§  YICA RMS Normä¼˜åŒ–åˆ†æ:")
    print(f"   ğŸ“ çŸ©é˜µç»´åº¦: {M}Ã—{N}")
    print(f"   ğŸ’¾ CIMé˜µåˆ—æ•°é‡: {YICA_CONFIG['num_cim_arrays']}")
    print(f"   ğŸ“ˆ åŸºç¡€ç‰ˆæœ¬å¸¦å®½: {yica_bandwidth:.1f}GB/s")
    print(f"   ğŸ”¥ èåˆç‰ˆæœ¬å¸¦å®½: {yica_fused_bandwidth:.1f}GB/s")
    print(f"   ğŸ’¿ SPMå¤§å°: {YICA_CONFIG['spm_size_kb']}KB")
    print(f"   ğŸ¯ å‘é‡åŒ–: {YICA_CONFIG['enable_vectorization']}")
    
    return {
        'mirage_time_ms': mirage_time,
        'yica_basic_time_ms': yica_time,
        'yica_fused_time_ms': yica_fused_time,
        'speedup_basic': speedup_basic,
        'speedup_fused': speedup_fused,
        'yica_bandwidth_gbps': yica_bandwidth,
        'yica_fused_bandwidth_gbps': yica_fused_bandwidth,
        'matrix_size': (M, N)
    }

def benchmark_different_sizes():
    """å¯¹ä¸åŒçŸ©é˜µå¤§å°è¿›è¡ŒåŸºå‡†æµ‹è¯•"""
    print("\nğŸ”¬ ä¸åŒçŸ©é˜µå¤§å°çš„æ€§èƒ½åˆ†æ")
    print("=" * 50)
    
    yica_rmsnorm = YICARMSNorm(YICA_CONFIG)
    sizes = [(1024, 1024), (2048, 2048), (4096, 4096), (8192, 4096)]
    
    results = []
    
    for M, N in sizes:
        print(f"\nğŸ“Š æµ‹è¯•çŸ©é˜µå¤§å°: {M}Ã—{N}")
        
        # å‡†å¤‡æ•°æ®
        X = torch.randn(M, N, dtype=torch.float16, device='cuda:0')
        W = torch.randn(N, dtype=torch.float16, device='cuda:0')
        
        # é¢„çƒ­
        for _ in range(10):
            yica_rmsnorm([X, W])
        
        torch.cuda.synchronize()
        
        # æµ‹è¯•
        starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)
        starter.record()
        for _ in range(100):
            yica_rmsnorm([X, W])
        ender.record()
        torch.cuda.synchronize()
        
        time_ms = starter.elapsed_time(ender) / 100
        bandwidth = (M * N * 3 * 2 / (time_ms * 1e-3)) / 1e9  # GB/s
        
        print(f"   â±ï¸  æ—¶é—´: {time_ms:.3f}ms")
        print(f"   ğŸ“ˆ å¸¦å®½: {bandwidth:.1f}GB/s")
        
        results.append({
            'size': (M, N),
            'time_ms': time_ms,
            'bandwidth_gbps': bandwidth
        })
    
    return results

if __name__ == "__main__":
    print("ğŸ§ª YICA RMS Normalizationæ¼”ç¤º")
    print("åŸºäºMirage demo_rms_norm.pyçš„YICAä¼˜åŒ–ç‰ˆæœ¬")
    print("=" * 80)
    
    try:
        # è¿è¡Œå¯¹æ¯”å®éªŒ
        results = run_yica_vs_mirage_rmsnorm_comparison()
        
        print(f"\nğŸ¯ å®éªŒæ€»ç»“:")
        if results['speedup_fused'] > 3.0:
            print(f"   ğŸ‰ YICAèåˆä¼˜åŒ–æ•ˆæœæä½³ï¼{results['speedup_fused']:.2f}xåŠ é€Ÿ")
        elif results['speedup_fused'] > 2.0:
            print(f"   ğŸš€ YICAèåˆä¼˜åŒ–æ•ˆæœæ˜¾è‘—ï¼{results['speedup_fused']:.2f}xåŠ é€Ÿ")
        elif results['speedup_fused'] > 1.5:
            print(f"   âœ… YICAèåˆä¼˜åŒ–æ•ˆæœè‰¯å¥½ï¼{results['speedup_fused']:.2f}xåŠ é€Ÿ")
        elif results['speedup_fused'] > 1.0:
            print(f"   âš ï¸  YICAæœ‰è½»å¾®ä¼˜åŒ–ï¼Œ{results['speedup_fused']:.2f}xåŠ é€Ÿ")
        else:
            print(f"   ğŸ“ YICA RMS Norméœ€è¦è¿›ä¸€æ­¥è°ƒä¼˜")
        
        print(f"\nğŸ“‹ YICA RMS Normç‰¹æ€§éªŒè¯:")
        print(f"   âœ… CIMé˜µåˆ—å¹¶è¡Œ: {YICA_CONFIG['num_cim_arrays']}ä¸ªé˜µåˆ—")
        print(f"   âœ… SPMå†…å­˜ä¼˜åŒ–: {YICA_CONFIG['spm_size_kb']}KB")
        print(f"   âœ… å­˜ç®—ä¸€ä½“å¹³æ–¹æ ¹")
        print(f"   âœ… å‘é‡åŒ–å¤„ç†")
        print(f"   âœ… æ®‹å·®è¿æ¥èåˆ")
        
        print(f"\nğŸ“š ä¸åŸå§‹demo_rms_norm.pyçš„æ”¹è¿›:")
        print(f"   ğŸ”§ å®ç°äº†çœŸæ­£çš„RMS Normç®—æ³•")
        print(f"   ğŸ”§ æ·»åŠ äº†CIMé˜µåˆ—å¹¶è¡ŒåŒ–")
        print(f"   ğŸ”§ ä¼˜åŒ–äº†å†…å­˜è®¿é—®æ¨¡å¼")
        print(f"   ğŸ”§ å®ç°äº†æ®‹å·®è¿æ¥èåˆ")
        print(f"   ğŸ”§ æ”¯æŒä¸åŒçŸ©é˜µå¤§å°")
        print(f"   ğŸ”§ å¢åŠ äº†è¯¦ç»†çš„æ€§èƒ½åˆ†æ")
        
        # è¿è¡Œå¤šå°ºå¯¸åŸºå‡†æµ‹è¯•
        size_results = benchmark_different_sizes()
        
        print(f"\nğŸ“Š å¤šå°ºå¯¸æ€§èƒ½æ€»ç»“:")
        for result in size_results:
            M, N = result['size']
            print(f"   {M}Ã—{N}: {result['time_ms']:.3f}ms, {result['bandwidth_gbps']:.1f}GB/s")
            
    except Exception as e:
        print(f"âŒ å®éªŒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        print("ğŸ’¡ è¿™å¯èƒ½æ˜¯å› ä¸ºéœ€è¦å®Œæ•´çš„Mirageç¯å¢ƒæˆ–CUDAè®¾å¤‡")
        print("   è¯·ç¡®ä¿å·²æ­£ç¡®å®‰è£…å’Œé…ç½®MirageåŠCUDAç¯å¢ƒ") 