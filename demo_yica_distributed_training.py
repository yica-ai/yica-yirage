#!/usr/bin/env python3
"""
YICA åˆ†å¸ƒå¼è®­ç»ƒæ¼”ç¤º

è¿™ä¸ªæ¼”ç¤ºå±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ YICA åˆ†å¸ƒå¼ä¼˜åŒ–å™¨å’Œ YCCL é€šä¿¡åº“è¿›è¡Œå¤§è§„æ¨¡æ·±åº¦å­¦ä¹ æ¨¡å‹è®­ç»ƒï¼š

1. å¤šè®¾å¤‡åˆ†å¸ƒå¼è®­ç»ƒè®¾ç½®
2. YCCL é€šä¿¡ä¼˜åŒ–æ¼”ç¤º
3. åŠ¨æ€è´Ÿè½½å‡è¡¡
4. å®¹é”™å’Œæ¢å¤æœºåˆ¶
5. æ€§èƒ½ç›‘æ§å’Œåˆ†æ
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, DistributedSampler
import torchvision.transforms as transforms
import torchvision.datasets as datasets

import os
import sys
import time
import argparse
import json
from typing import Dict, List, Any
import numpy as np
import matplotlib.pyplot as plt
from dataclasses import asdict

# æ·»åŠ  Mirage è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), 'mirage', 'python'))

from mirage.yica.config import YICAConfig
from mirage.python.mirage.yica_distributed_optimizer import (
    YICADistributedOptimizer, DistributedTrainingConfig, DistributedMetrics
)
from mirage.python.mirage.yica_llama_optimizer import YICALlamaOptimizer, LlamaModelConfig


class YICADistributedTrainingDemo:
    """YICA åˆ†å¸ƒå¼è®­ç»ƒæ¼”ç¤ºç±»"""
    
    def __init__(self, args):
        self.args = args
        self.device = None
        self.model = None
        self.optimizer = None
        self.train_loader = None
        self.val_loader = None
        self.dist_optimizer = None
        
        # é…ç½®å‚æ•°
        self.yica_config = YICAConfig(
            num_cim_arrays=args.num_cim_arrays,
            spm_size_per_die=args.spm_size * 1024 * 1024,  # MB to bytes
            dram_size_per_cluster=args.dram_size * 1024 * 1024 * 1024,  # GB to bytes
            enable_quantization=args.enable_quantization,
            target_precision=args.precision
        )
        
        self.distributed_config = DistributedTrainingConfig(
            world_size=args.world_size,
            rank=args.rank,
            local_rank=args.local_rank,
            backend=args.backend,
            data_parallel=args.data_parallel,
            model_parallel=args.model_parallel,
            gradient_compression=args.gradient_compression,
            gradient_clipping=args.gradient_clipping,
            dynamic_load_balancing=args.dynamic_load_balancing,
            fault_tolerance=args.fault_tolerance,
            enable_profiling=args.enable_profiling
        )
        
        # æ€§èƒ½ç»Ÿè®¡
        self.training_metrics = []
        self.communication_stats = []
        
    def setup_model_and_data(self):
        """è®¾ç½®æ¨¡å‹å’Œæ•°æ®"""
        print(f"ğŸ—ï¸  è®¾ç½®æ¨¡å‹å’Œæ•°æ® (Rank {self.args.rank})")
        
        # åˆ›å»ºæ¨¡å‹
        if self.args.model_type == "resnet":
            self.model = self._create_resnet_model()
        elif self.args.model_type == "transformer":
            self.model = self._create_transformer_model()
        elif self.args.model_type == "llama":
            self.model = self._create_llama_model()
        else:
            raise ValueError(f"Unsupported model type: {self.args.model_type}")
        
        print(f"ğŸ“Š æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in self.model.parameters()):,}")
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        if self.args.dataset == "cifar10":
            self.train_loader, self.val_loader = self._create_cifar10_loaders()
        elif self.args.dataset == "imagenet":
            self.train_loader, self.val_loader = self._create_imagenet_loaders()
        elif self.args.dataset == "synthetic":
            self.train_loader, self.val_loader = self._create_synthetic_loaders()
        
        # åˆ›å»ºä¼˜åŒ–å™¨
        self.optimizer = optim.AdamW(
            self.model.parameters(),
            lr=self.args.learning_rate,
            weight_decay=self.args.weight_decay
        )
        
        # åˆ›å»ºåˆ†å¸ƒå¼ä¼˜åŒ–å™¨
        self.dist_optimizer = YICADistributedOptimizer(
            self.model, self.yica_config, self.distributed_config
        )
        
        print("âœ… æ¨¡å‹å’Œæ•°æ®è®¾ç½®å®Œæˆ")
    
    def _create_resnet_model(self):
        """åˆ›å»º ResNet æ¨¡å‹"""
        if self.args.model_size == "small":
            return nn.Sequential(
                nn.Conv2d(3, 64, 7, stride=2, padding=3),
                nn.BatchNorm2d(64),
                nn.ReLU(),
                nn.MaxPool2d(3, stride=2, padding=1),
                *self._make_resnet_layer(64, 128, 2),
                *self._make_resnet_layer(128, 256, 2),
                nn.AdaptiveAvgPool2d((1, 1)),
                nn.Flatten(),
                nn.Linear(256, self.args.num_classes)
            )
        elif self.args.model_size == "medium":
            return nn.Sequential(
                nn.Conv2d(3, 64, 7, stride=2, padding=3),
                nn.BatchNorm2d(64),
                nn.ReLU(),
                nn.MaxPool2d(3, stride=2, padding=1),
                *self._make_resnet_layer(64, 128, 3),
                *self._make_resnet_layer(128, 256, 4),
                *self._make_resnet_layer(256, 512, 6),
                nn.AdaptiveAvgPool2d((1, 1)),
                nn.Flatten(),
                nn.Linear(512, self.args.num_classes)
            )
        else:  # large
            return nn.Sequential(
                nn.Conv2d(3, 64, 7, stride=2, padding=3),
                nn.BatchNorm2d(64),
                nn.ReLU(),
                nn.MaxPool2d(3, stride=2, padding=1),
                *self._make_resnet_layer(64, 128, 3),
                *self._make_resnet_layer(128, 256, 4),
                *self._make_resnet_layer(256, 512, 6),
                *self._make_resnet_layer(512, 1024, 3),
                nn.AdaptiveAvgPool2d((1, 1)),
                nn.Flatten(),
                nn.Linear(1024, self.args.num_classes)
            )
    
    def _make_resnet_layer(self, in_channels, out_channels, num_blocks):
        """åˆ›å»º ResNet å±‚"""
        layers = []
        for i in range(num_blocks):
            if i == 0:
                layers.append(nn.Conv2d(in_channels, out_channels, 3, stride=2, padding=1))
            else:
                layers.append(nn.Conv2d(out_channels, out_channels, 3, padding=1))
            layers.append(nn.BatchNorm2d(out_channels))
            layers.append(nn.ReLU())
        return layers
    
    def _create_transformer_model(self):
        """åˆ›å»º Transformer æ¨¡å‹"""
        if self.args.model_size == "small":
            hidden_size, num_layers, num_heads = 512, 6, 8
        elif self.args.model_size == "medium":
            hidden_size, num_layers, num_heads = 768, 12, 12
        else:  # large
            hidden_size, num_layers, num_heads = 1024, 24, 16
        
        return nn.Sequential(
            nn.Embedding(self.args.vocab_size, hidden_size),
            *[nn.TransformerEncoderLayer(
                d_model=hidden_size,
                nhead=num_heads,
                dim_feedforward=hidden_size * 4,
                batch_first=True
            ) for _ in range(num_layers)],
            nn.LayerNorm(hidden_size),
            nn.Linear(hidden_size, self.args.num_classes)
        )
    
    def _create_llama_model(self):
        """åˆ›å»º Llama æ¨¡å‹"""
        if self.args.model_size == "small":
            model_config = LlamaModelConfig(
                hidden_size=768, num_hidden_layers=12, num_attention_heads=12
            )
        elif self.args.model_size == "medium":
            model_config = LlamaModelConfig(
                hidden_size=1024, num_hidden_layers=24, num_attention_heads=16
            )
        else:  # large
            model_config = LlamaModelConfig(
                hidden_size=2048, num_hidden_layers=32, num_attention_heads=32
            )
        
        # ç®€åŒ–çš„ Llama æ¨¡å‹å®ç°
        class SimplifiedLlama(nn.Module):
            def __init__(self, config):
                super().__init__()
                self.config = config
                self.embed = nn.Embedding(config.vocab_size, config.hidden_size)
                self.layers = nn.ModuleList([
                    nn.TransformerDecoderLayer(
                        d_model=config.hidden_size,
                        nhead=config.num_attention_heads,
                        dim_feedforward=config.intermediate_size,
                        batch_first=True
                    ) for _ in range(config.num_hidden_layers)
                ])
                self.norm = nn.LayerNorm(config.hidden_size)
                self.lm_head = nn.Linear(config.hidden_size, config.vocab_size)
            
            def forward(self, input_ids, attention_mask=None):
                x = self.embed(input_ids)
                for layer in self.layers:
                    x = layer(x, x, tgt_mask=attention_mask)
                x = self.norm(x)
                return self.lm_head(x)
        
        return SimplifiedLlama(model_config)
    
    def _create_cifar10_loaders(self):
        """åˆ›å»º CIFAR-10 æ•°æ®åŠ è½½å™¨"""
        transform_train = transforms.Compose([
            transforms.RandomCrop(32, padding=4),
            transforms.RandomHorizontalFlip(),
            transforms.ToTensor(),
            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))
        ])
        
        transform_val = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))
        ])
        
        train_dataset = datasets.CIFAR10(
            root='./data', train=True, download=True, transform=transform_train
        )
        val_dataset = datasets.CIFAR10(
            root='./data', train=False, download=True, transform=transform_val
        )
        
        train_sampler = DistributedSampler(train_dataset) if self.args.world_size > 1 else None
        val_sampler = DistributedSampler(val_dataset) if self.args.world_size > 1 else None
        
        train_loader = DataLoader(
            train_dataset, batch_size=self.args.batch_size,
            sampler=train_sampler, shuffle=(train_sampler is None),
            num_workers=4, pin_memory=True
        )
        
        val_loader = DataLoader(
            val_dataset, batch_size=self.args.batch_size,
            sampler=val_sampler, shuffle=False,
            num_workers=4, pin_memory=True
        )
        
        return train_loader, val_loader
    
    def _create_synthetic_loaders(self):
        """åˆ›å»ºåˆæˆæ•°æ®åŠ è½½å™¨"""
        class SyntheticDataset(torch.utils.data.Dataset):
            def __init__(self, size, input_shape, num_classes):
                self.size = size
                self.input_shape = input_shape
                self.num_classes = num_classes
            
            def __len__(self):
                return self.size
            
            def __getitem__(self, idx):
                if len(self.input_shape) == 3:  # å›¾åƒæ•°æ®
                    x = torch.randn(self.input_shape)
                else:  # åºåˆ—æ•°æ®
                    x = torch.randint(0, 1000, self.input_shape)
                y = torch.randint(0, self.num_classes, ())
                return x, y
        
        if self.args.model_type in ["resnet"]:
            input_shape = (3, 32, 32)
        elif self.args.model_type in ["transformer", "llama"]:
            input_shape = (self.args.sequence_length,)
        else:
            input_shape = (3, 32, 32)
        
        train_dataset = SyntheticDataset(10000, input_shape, self.args.num_classes)
        val_dataset = SyntheticDataset(2000, input_shape, self.args.num_classes)
        
        train_sampler = DistributedSampler(train_dataset) if self.args.world_size > 1 else None
        val_sampler = DistributedSampler(val_dataset) if self.args.world_size > 1 else None
        
        train_loader = DataLoader(
            train_dataset, batch_size=self.args.batch_size,
            sampler=train_sampler, shuffle=(train_sampler is None),
            num_workers=2
        )
        
        val_loader = DataLoader(
            val_dataset, batch_size=self.args.batch_size,
            sampler=val_sampler, shuffle=False,
            num_workers=2
        )
        
        return train_loader, val_loader
    
    def run_distributed_training(self):
        """è¿è¡Œåˆ†å¸ƒå¼è®­ç»ƒ"""
        print(f"ğŸš€ å¼€å§‹åˆ†å¸ƒå¼è®­ç»ƒ (Rank {self.args.rank})")
        
        # åˆå§‹åŒ–åˆ†å¸ƒå¼ç¯å¢ƒ
        self.dist_optimizer.initialize_distributed()
        
        # ä¼˜åŒ–æ¨¡å‹åˆ†å¸ƒç­–ç•¥
        distribution_plan = self.dist_optimizer.optimize_model_distribution()
        print(f"ğŸ“Š åˆ†å¸ƒç­–ç•¥: {distribution_plan}")
        
        # è®­ç»ƒå¾ªç¯
        for epoch in range(self.args.epochs):
            print(f"\nğŸ“ˆ Epoch {epoch + 1}/{self.args.epochs}")
            
            # è®­ç»ƒä¸€ä¸ª epoch
            train_metrics = self._train_epoch(epoch)
            
            # éªŒè¯
            if (epoch + 1) % self.args.eval_interval == 0:
                val_metrics = self._validate_epoch(epoch)
                print(f"ğŸ¯ éªŒè¯å‡†ç¡®ç‡: {val_metrics['accuracy']:.4f}")
            
            # ä¿å­˜æ£€æŸ¥ç‚¹
            if (epoch + 1) % self.args.checkpoint_interval == 0:
                self._save_checkpoint(epoch)
            
            # æ”¶é›†åˆ†å¸ƒå¼æŒ‡æ ‡
            dist_metrics = self.dist_optimizer.get_distributed_metrics()
            self._log_distributed_metrics(epoch, dist_metrics)
        
        # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        self._generate_final_report()
        
        # æ¸…ç†
        self.dist_optimizer.finalize()
        
        print("ğŸ‰ åˆ†å¸ƒå¼è®­ç»ƒå®Œæˆ!")
    
    def _train_epoch(self, epoch: int) -> Dict[str, float]:
        """è®­ç»ƒä¸€ä¸ª epoch"""
        self.model.train()
        
        total_loss = 0.0
        total_samples = 0
        epoch_start_time = time.time()
        
        for batch_idx, (data, target) in enumerate(self.train_loader):
            batch_start_time = time.time()
            
            # å‡†å¤‡æ•°æ®
            if torch.cuda.is_available():
                data = data.cuda(non_blocking=True)
                target = target.cuda(non_blocking=True)
            
            # åˆ›å»ºæ‰¹æ¬¡å­—å…¸
            if self.args.model_type in ["transformer", "llama"]:
                batch = {'input_ids': data, 'labels': target}
            else:
                # å¯¹äº CNN æ¨¡å‹ï¼Œéœ€è¦æ‰‹åŠ¨è®¡ç®—æŸå¤±
                outputs = self.model(data)
                loss = nn.CrossEntropyLoss()(outputs, target)
                batch = {'loss': loss}
            
            # æ‰§è¡Œè®­ç»ƒæ­¥éª¤
            if self.args.model_type in ["transformer", "llama"]:
                step_metrics = self.dist_optimizer.train_step(batch, self.optimizer)
            else:
                # æ‰‹åŠ¨æ‰§è¡Œè®­ç»ƒæ­¥éª¤
                self.optimizer.zero_grad()
                loss.backward()
                self.optimizer.step()
                
                step_metrics = {
                    'loss': loss.item(),
                    'forward_time': 0.01,
                    'backward_time': 0.01,
                    'communication_time': 0.001,
                    'optimization_time': 0.001,
                    'total_time': time.time() - batch_start_time
                }
            
            total_loss += step_metrics['loss']
            total_samples += data.size(0)
            
            # æ‰“å°è¿›åº¦
            if batch_idx % self.args.log_interval == 0:
                print(f"  Batch {batch_idx}/{len(self.train_loader)}: "
                      f"Loss={step_metrics['loss']:.6f}, "
                      f"Comm={step_metrics['communication_time']*1000:.2f}ms, "
                      f"Total={step_metrics['total_time']*1000:.2f}ms")
            
            # è®°å½•æŒ‡æ ‡
            self.training_metrics.append({
                'epoch': epoch,
                'batch': batch_idx,
                **step_metrics
            })
        
        epoch_time = time.time() - epoch_start_time
        avg_loss = total_loss / len(self.train_loader)
        
        print(f"ğŸ“Š Epoch {epoch + 1} è®­ç»ƒå®Œæˆ: "
              f"å¹³å‡æŸå¤±={avg_loss:.6f}, "
              f"è€—æ—¶={epoch_time:.2f}s")
        
        return {
            'loss': avg_loss,
            'epoch_time': epoch_time,
            'samples_per_second': total_samples / epoch_time
        }
    
    def _validate_epoch(self, epoch: int) -> Dict[str, float]:
        """éªŒè¯ä¸€ä¸ª epoch"""
        self.model.eval()
        
        total_loss = 0.0
        correct = 0
        total_samples = 0
        
        with torch.no_grad():
            for data, target in self.val_loader:
                if torch.cuda.is_available():
                    data = data.cuda(non_blocking=True)
                    target = target.cuda(non_blocking=True)
                
                outputs = self.model(data)
                
                if isinstance(outputs, tuple):
                    outputs = outputs[0]  # å– logits
                
                loss = nn.CrossEntropyLoss()(outputs, target)
                total_loss += loss.item()
                
                pred = outputs.argmax(dim=1)
                correct += pred.eq(target).sum().item()
                total_samples += data.size(0)
        
        avg_loss = total_loss / len(self.val_loader)
        accuracy = correct / total_samples
        
        return {
            'loss': avg_loss,
            'accuracy': accuracy
        }
    
    def _save_checkpoint(self, epoch: int):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        if self.args.rank == 0:  # åªæœ‰ä¸»è¿›ç¨‹ä¿å­˜
            checkpoint_path = f"checkpoint_epoch_{epoch + 1}.pt"
            self.dist_optimizer.save_checkpoint(checkpoint_path, epoch, 0)
    
    def _log_distributed_metrics(self, epoch: int, metrics: DistributedMetrics):
        """è®°å½•åˆ†å¸ƒå¼æŒ‡æ ‡"""
        if self.args.rank == 0:
            print(f"ğŸ”§ åˆ†å¸ƒå¼æŒ‡æ ‡ (Epoch {epoch + 1}):")
            print(f"  é€šä¿¡æ•ˆç‡: {metrics.communication_efficiency:.4f}")
            print(f"  è®¡ç®—æ•ˆç‡: {metrics.computation_efficiency:.4f}")
            print(f"  æ•´ä½“æ•ˆç‡: {metrics.overall_efficiency:.4f}")
            print(f"  é€šä¿¡æ—¶é—´: {metrics.total_communication_time:.4f}s")
    
    def _generate_final_report(self):
        """ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"""
        if self.args.rank != 0:
            return
        
        print("\n" + "="*60)
        print("ğŸ“Š YICA åˆ†å¸ƒå¼è®­ç»ƒæœ€ç»ˆæŠ¥å‘Š")
        print("="*60)
        
        # è®¡ç®—æ€»ä½“ç»Ÿè®¡
        if self.training_metrics:
            avg_loss = np.mean([m['loss'] for m in self.training_metrics[-100:]])  # æœ€å100ä¸ªbatch
            avg_comm_time = np.mean([m['communication_time'] for m in self.training_metrics])
            avg_total_time = np.mean([m['total_time'] for m in self.training_metrics])
            
            print(f"ğŸ¯ è®­ç»ƒç»Ÿè®¡:")
            print(f"  æœ€ç»ˆæŸå¤±: {avg_loss:.6f}")
            print(f"  å¹³å‡é€šä¿¡æ—¶é—´: {avg_comm_time*1000:.2f}ms")
            print(f"  å¹³å‡æ‰¹æ¬¡æ—¶é—´: {avg_total_time*1000:.2f}ms")
            print(f"  é€šä¿¡å¼€é”€å æ¯”: {avg_comm_time/avg_total_time*100:.2f}%")
        
        # åˆ†å¸ƒå¼æŒ‡æ ‡
        dist_metrics = self.dist_optimizer.get_distributed_metrics()
        print(f"\nğŸ”§ åˆ†å¸ƒå¼æ€§èƒ½:")
        print(f"  é€šä¿¡æ•ˆç‡: {dist_metrics.communication_efficiency:.4f}")
        print(f"  è®¡ç®—æ•ˆç‡: {dist_metrics.computation_efficiency:.4f}")
        print(f"  æ•´ä½“æ•ˆç‡: {dist_metrics.overall_efficiency:.4f}")
        
        # ç¡¬ä»¶åˆ©ç”¨ç‡
        print(f"\nğŸ—ï¸  YICA ç¡¬ä»¶åˆ©ç”¨:")
        print(f"  CIM é˜µåˆ—æ•°é‡: {self.yica_config.num_cim_arrays}")
        print(f"  SPM å®¹é‡: {self.yica_config.spm_size_per_die // (1024*1024)}MB")
        print(f"  é‡åŒ–å¯ç”¨: {self.yica_config.enable_quantization}")
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        results = {
            'training_metrics': self.training_metrics,
            'distributed_metrics': asdict(dist_metrics),
            'yica_config': asdict(self.yica_config),
            'distributed_config': asdict(self.distributed_config)
        }
        
        with open('yica_distributed_training_results.json', 'w') as f:
            json.dump(results, f, indent=2, default=str)
        
        print(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: yica_distributed_training_results.json")
        print("="*60)
    
    def run_communication_benchmark(self):
        """è¿è¡Œé€šä¿¡åŸºå‡†æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹ YCCL é€šä¿¡åŸºå‡†æµ‹è¯•")
        
        # åˆå§‹åŒ–åˆ†å¸ƒå¼ç¯å¢ƒ
        self.dist_optimizer.initialize_distributed()
        
        # æµ‹è¯•ä¸åŒå¤§å°çš„æ¶ˆæ¯
        message_sizes = [1024, 4096, 16384, 65536, 262144, 1048576]  # 1KB to 1MB
        
        results = {}
        
        for size in message_sizes:
            print(f"ğŸ“Š æµ‹è¯•æ¶ˆæ¯å¤§å°: {size} bytes")
            
            # åˆ›å»ºæµ‹è¯•æ•°æ®
            data = torch.randn(size // 4, dtype=torch.float32)  # 4 bytes per float
            if torch.cuda.is_available():
                data = data.cuda()
            
            # AllReduce åŸºå‡†æµ‹è¯•
            all_reduce_times = []
            for _ in range(10):  # 10 æ¬¡æµ‹è¯•
                start_time = time.time()
                
                # æ¨¡æ‹Ÿ AllReduce æ“ä½œ
                if torch.distributed.is_initialized():
                    torch.distributed.all_reduce(data)
                
                end_time = time.time()
                all_reduce_times.append(end_time - start_time)
            
            avg_time = np.mean(all_reduce_times)
            bandwidth = size / avg_time / (1024 * 1024)  # MB/s
            
            results[size] = {
                'all_reduce_time': avg_time,
                'bandwidth': bandwidth
            }
            
            print(f"  AllReduce æ—¶é—´: {avg_time*1000:.2f}ms")
            print(f"  æœ‰æ•ˆå¸¦å®½: {bandwidth:.2f} MB/s")
        
        # ç”Ÿæˆé€šä¿¡åŸºå‡†æµ‹è¯•æŠ¥å‘Š
        self._generate_communication_report(results)
        
        # æ¸…ç†
        self.dist_optimizer.finalize()
        
        print("âœ… YCCL é€šä¿¡åŸºå‡†æµ‹è¯•å®Œæˆ")
    
    def _generate_communication_report(self, results: Dict[int, Dict[str, float]]):
        """ç”Ÿæˆé€šä¿¡åŸºå‡†æµ‹è¯•æŠ¥å‘Š"""
        if self.args.rank != 0:
            return
        
        print("\n" + "="*50)
        print("ğŸ“¡ YCCL é€šä¿¡åŸºå‡†æµ‹è¯•æŠ¥å‘Š")
        print("="*50)
        
        sizes = sorted(results.keys())
        times = [results[s]['all_reduce_time'] * 1000 for s in sizes]  # ms
        bandwidths = [results[s]['bandwidth'] for s in sizes]
        
        print("æ¶ˆæ¯å¤§å° (KB) | AllReduceæ—¶é—´ (ms) | å¸¦å®½ (MB/s)")
        print("-" * 50)
        for i, size in enumerate(sizes):
            print(f"{size//1024:>10} | {times[i]:>15.2f} | {bandwidths[i]:>10.2f}")
        
        print(f"\nğŸ“ˆ æ€§èƒ½æ‘˜è¦:")
        print(f"  æœ€å¤§å¸¦å®½: {max(bandwidths):.2f} MB/s")
        print(f"  æœ€å°å»¶è¿Ÿ: {min(times):.2f} ms")
        print(f"  å¹³å‡å¸¦å®½: {np.mean(bandwidths):.2f} MB/s")
        
        # ä¿å­˜ç»“æœ
        with open('yccl_communication_benchmark.json', 'w') as f:
            json.dump(results, f, indent=2)
        
        print(f"\nğŸ’¾ åŸºå‡†æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: yccl_communication_benchmark.json")
        print("="*50)


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description="YICA åˆ†å¸ƒå¼è®­ç»ƒæ¼”ç¤º")
    
    # åˆ†å¸ƒå¼é…ç½®
    parser.add_argument('--world-size', type=int, default=1, help='åˆ†å¸ƒå¼è®­ç»ƒä¸–ç•Œå¤§å°')
    parser.add_argument('--rank', type=int, default=0, help='å½“å‰è¿›ç¨‹æ’å')
    parser.add_argument('--local-rank', type=int, default=0, help='æœ¬åœ°è¿›ç¨‹æ’å')
    parser.add_argument('--backend', type=str, default='yccl', choices=['nccl', 'gloo', 'yccl'],
                       help='åˆ†å¸ƒå¼åç«¯')
    
    # æ¨¡å‹é…ç½®
    parser.add_argument('--model-type', type=str, default='resnet', 
                       choices=['resnet', 'transformer', 'llama'], help='æ¨¡å‹ç±»å‹')
    parser.add_argument('--model-size', type=str, default='small',
                       choices=['small', 'medium', 'large'], help='æ¨¡å‹å¤§å°')
    parser.add_argument('--num-classes', type=int, default=10, help='åˆ†ç±»æ•°é‡')
    parser.add_argument('--vocab-size', type=int, default=32000, help='è¯æ±‡è¡¨å¤§å°')
    parser.add_argument('--sequence-length', type=int, default=512, help='åºåˆ—é•¿åº¦')
    
    # è®­ç»ƒé…ç½®
    parser.add_argument('--dataset', type=str, default='synthetic',
                       choices=['cifar10', 'imagenet', 'synthetic'], help='æ•°æ®é›†')
    parser.add_argument('--batch-size', type=int, default=32, help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--epochs', type=int, default=5, help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--learning-rate', type=float, default=1e-3, help='å­¦ä¹ ç‡')
    parser.add_argument('--weight-decay', type=float, default=1e-4, help='æƒé‡è¡°å‡')
    
    # YICA ç¡¬ä»¶é…ç½®
    parser.add_argument('--num-cim-arrays', type=int, default=16, help='CIM é˜µåˆ—æ•°é‡')
    parser.add_argument('--spm-size', type=int, default=128, help='SPM å¤§å° (MB)')
    parser.add_argument('--dram-size', type=int, default=16, help='DRAM å¤§å° (GB)')
    parser.add_argument('--enable-quantization', action='store_true', help='å¯ç”¨é‡åŒ–')
    parser.add_argument('--precision', type=str, default='fp16', choices=['fp32', 'fp16', 'int8'],
                       help='è®¡ç®—ç²¾åº¦')
    
    # åˆ†å¸ƒå¼ä¼˜åŒ–é…ç½®
    parser.add_argument('--data-parallel', action='store_true', default=True, help='æ•°æ®å¹¶è¡Œ')
    parser.add_argument('--model-parallel', action='store_true', help='æ¨¡å‹å¹¶è¡Œ')
    parser.add_argument('--gradient-compression', action='store_true', help='æ¢¯åº¦å‹ç¼©')
    parser.add_argument('--gradient-clipping', type=float, default=1.0, help='æ¢¯åº¦è£å‰ª')
    parser.add_argument('--dynamic-load-balancing', action='store_true', help='åŠ¨æ€è´Ÿè½½å‡è¡¡')
    parser.add_argument('--fault-tolerance', action='store_true', help='å®¹é”™æœºåˆ¶')
    parser.add_argument('--enable-profiling', action='store_true', help='å¯ç”¨æ€§èƒ½åˆ†æ')
    
    # å…¶ä»–é…ç½®
    parser.add_argument('--log-interval', type=int, default=10, help='æ—¥å¿—é—´éš”')
    parser.add_argument('--eval-interval', type=int, default=1, help='è¯„ä¼°é—´éš”')
    parser.add_argument('--checkpoint-interval', type=int, default=5, help='æ£€æŸ¥ç‚¹é—´éš”')
    parser.add_argument('--mode', type=str, default='train', choices=['train', 'benchmark'],
                       help='è¿è¡Œæ¨¡å¼')
    
    return parser.parse_args()


def main():
    """ä¸»å‡½æ•°"""
    args = parse_arguments()
    
    print("ğŸš€ YICA åˆ†å¸ƒå¼è®­ç»ƒæ¼”ç¤ºå¯åŠ¨")
    print(f"ğŸ“Š é…ç½®: {args.world_size} è®¾å¤‡, {args.backend} åç«¯, {args.model_type} æ¨¡å‹")
    print(f"ğŸ”§ YICA: {args.num_cim_arrays} CIMé˜µåˆ—, {args.smp_size}MB SPM, {args.precision} ç²¾åº¦")
    
    # åˆ›å»ºæ¼”ç¤ºå®ä¾‹
    demo = YICADistributedTrainingDemo(args)
    
    try:
        # è®¾ç½®æ¨¡å‹å’Œæ•°æ®
        demo.setup_model_and_data()
        
        if args.mode == 'train':
            # è¿è¡Œåˆ†å¸ƒå¼è®­ç»ƒ
            demo.run_distributed_training()
        elif args.mode == 'benchmark':
            # è¿è¡Œé€šä¿¡åŸºå‡†æµ‹è¯•
            demo.run_communication_benchmark()
            
    except KeyboardInterrupt:
        print("\nâš ï¸  è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
    finally:
        print("ğŸ§¹ æ¸…ç†èµ„æº...")
        if demo.dist_optimizer and demo.dist_optimizer.is_initialized:
            demo.dist_optimizer.finalize()
    
    print("âœ… YICA åˆ†å¸ƒå¼è®­ç»ƒæ¼”ç¤ºå®Œæˆ")


if __name__ == "__main__":
    main() 