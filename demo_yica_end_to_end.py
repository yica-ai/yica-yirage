#!/usr/bin/env python3
"""
YICA-Mirage ç«¯åˆ°ç«¯æ¼”ç¤ºåº”ç”¨
==========================

å±•ç¤º YICA ç¡¬ä»¶åŠ é€Ÿçš„å®Œæ•´ AI æ¨ç†æµç¨‹ï¼ŒåŒ…æ‹¬æ¨¡å‹åŠ è½½ã€ä¼˜åŒ–ã€æ¨ç†å’Œæ€§èƒ½åˆ†æã€‚
æ”¯æŒå¤šç§æ¨¡å‹æ¶æ„ï¼šLlamaã€BERTã€ResNet ç­‰ï¼Œå±•ç¤º YICA çš„ä¼˜åŒ–æ•ˆæœã€‚
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import time
import logging
import argparse
import json
import os
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@dataclass
class BenchmarkResult:
    """åŸºå‡†æµ‹è¯•ç»“æœ"""
    model_name: str
    batch_size: int
    sequence_length: int
    latency_ms: float
    throughput_tokens_per_sec: float
    memory_usage_mb: float
    peak_memory_mb: float
    energy_consumption_j: Optional[float] = None
    optimization_speedup: Optional[float] = None

class YICALlamaDemo(nn.Module):
    """YICA ä¼˜åŒ–çš„ç®€åŒ– Llama æ¨¡å‹æ¼”ç¤º"""
    
    def __init__(self, vocab_size=32000, hidden_size=512, num_layers=6, num_heads=8):
        super().__init__()
        self.hidden_size = hidden_size
        self.num_heads = num_heads
        self.num_layers = num_layers
        
        # åµŒå…¥å±‚
        self.token_embedding = nn.Embedding(vocab_size, hidden_size)
        self.position_embedding = nn.Embedding(2048, hidden_size)
        
        # Transformer å±‚
        self.layers = nn.ModuleList([
            YICALlamaLayer(hidden_size, num_heads) for _ in range(num_layers)
        ])
        
        # è¾“å‡ºå±‚
        self.ln_f = nn.LayerNorm(hidden_size)
        self.lm_head = nn.Linear(hidden_size, vocab_size, bias=False)
        
        logger.info(f"åˆ›å»º YICA Llama æ¨¡å‹: {num_layers} å±‚, {hidden_size} ç»´, {num_heads} å¤´")
    
    def forward(self, input_ids, attention_mask=None):
        batch_size, seq_len = input_ids.shape
        
        # ä½ç½®ç¼–ç 
        position_ids = torch.arange(seq_len, dtype=torch.long, device=input_ids.device)
        position_ids = position_ids.unsqueeze(0).expand(batch_size, -1)
        
        # åµŒå…¥
        token_embeds = self.token_embedding(input_ids)
        pos_embeds = self.position_embedding(position_ids)
        hidden_states = token_embeds + pos_embeds
        
        # Transformer å±‚
        for layer in self.layers:
            hidden_states = layer(hidden_states, attention_mask)
        
        # æœ€ç»ˆå±‚å½’ä¸€åŒ–å’Œè¾“å‡º
        hidden_states = self.ln_f(hidden_states)
        logits = self.lm_head(hidden_states)
        
        return logits

class YICALlamaLayer(nn.Module):
    """YICA ä¼˜åŒ–çš„ Llama å±‚"""
    
    def __init__(self, hidden_size, num_heads):
        super().__init__()
        self.hidden_size = hidden_size
        self.num_heads = num_heads
        self.head_dim = hidden_size // num_heads
        
        # Self-attention
        self.self_attn = YICAMultiHeadAttention(hidden_size, num_heads)
        
        # Feed-forward network
        self.mlp = YICAGatedMLP(hidden_size)
        
        # Layer normalization
        self.input_layernorm = nn.LayerNorm(hidden_size)
        self.post_attention_layernorm = nn.LayerNorm(hidden_size)
    
    def forward(self, hidden_states, attention_mask=None):
        # Self-attention
        residual = hidden_states
        hidden_states = self.input_layernorm(hidden_states)
        hidden_states = self.self_attn(hidden_states, attention_mask)
        hidden_states = residual + hidden_states
        
        # Feed-forward
        residual = hidden_states
        hidden_states = self.post_attention_layernorm(hidden_states)
        hidden_states = self.mlp(hidden_states)
        hidden_states = residual + hidden_states
        
        return hidden_states

class YICAMultiHeadAttention(nn.Module):
    """YICA ä¼˜åŒ–çš„å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶"""
    
    def __init__(self, hidden_size, num_heads):
        super().__init__()
        self.hidden_size = hidden_size
        self.num_heads = num_heads
        self.head_dim = hidden_size // num_heads
        
        # èåˆçš„ QKV æŠ•å½±ï¼ˆYICA ä¼˜åŒ–ï¼‰
        self.qkv_proj = nn.Linear(hidden_size, 3 * hidden_size, bias=False)
        self.o_proj = nn.Linear(hidden_size, hidden_size, bias=False)
        
        self.scale = self.head_dim ** -0.5
    
    def forward(self, hidden_states, attention_mask=None):
        batch_size, seq_len, _ = hidden_states.shape
        
        # èåˆ QKV è®¡ç®—
        qkv = self.qkv_proj(hidden_states)
        qkv = qkv.reshape(batch_size, seq_len, 3, self.num_heads, self.head_dim)
        q, k, v = qkv.unbind(dim=2)
        
        # é‡æ’ç»´åº¦ä»¥è¿›è¡Œæ³¨æ„åŠ›è®¡ç®—
        q = q.transpose(1, 2)  # (batch, heads, seq_len, head_dim)
        k = k.transpose(1, 2)
        v = v.transpose(1, 2)
        
        # è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°
        attn_weights = torch.matmul(q, k.transpose(-2, -1)) * self.scale
        
        if attention_mask is not None:
            attn_weights = attn_weights + attention_mask
        
        attn_weights = F.softmax(attn_weights, dim=-1)
        
        # åº”ç”¨æ³¨æ„åŠ›åˆ°å€¼
        attn_output = torch.matmul(attn_weights, v)
        
        # é‡æ–°ç»„åˆå¤´
        attn_output = attn_output.transpose(1, 2).contiguous()
        attn_output = attn_output.reshape(batch_size, seq_len, self.hidden_size)
        
        # è¾“å‡ºæŠ•å½±
        output = self.o_proj(attn_output)
        
        return output

class YICAGatedMLP(nn.Module):
    """YICA ä¼˜åŒ–çš„é—¨æ§ MLP"""
    
    def __init__(self, hidden_size, intermediate_size=None):
        super().__init__()
        if intermediate_size is None:
            intermediate_size = int(hidden_size * 8 / 3)  # Llama é£æ ¼
        
        self.gate_proj = nn.Linear(hidden_size, intermediate_size, bias=False)
        self.up_proj = nn.Linear(hidden_size, intermediate_size, bias=False)
        self.down_proj = nn.Linear(intermediate_size, hidden_size, bias=False)
        
        # YICA ç¡¬ä»¶ä¼˜åŒ–çš„ SiLU æ¿€æ´»å‡½æ•°
        self.activation = nn.SiLU()
    
    def forward(self, x):
        # é—¨æ§æœºåˆ¶
        gate = self.activation(self.gate_proj(x))
        up = self.up_proj(x)
        
        # èåˆè®¡ç®—
        intermediate = gate * up
        
        # ä¸‹æŠ•å½±
        output = self.down_proj(intermediate)
        
        return output

class YICABERTDemo(nn.Module):
    """YICA ä¼˜åŒ–çš„ç®€åŒ– BERT æ¨¡å‹æ¼”ç¤º"""
    
    def __init__(self, vocab_size=30522, hidden_size=768, num_layers=12, num_heads=12):
        super().__init__()
        self.hidden_size = hidden_size
        
        # åµŒå…¥å±‚
        self.embeddings = nn.ModuleDict({
            'word_embeddings': nn.Embedding(vocab_size, hidden_size),
            'position_embeddings': nn.Embedding(512, hidden_size),
            'token_type_embeddings': nn.Embedding(2, hidden_size),
            'LayerNorm': nn.LayerNorm(hidden_size),
            'dropout': nn.Dropout(0.1)
        })
        
        # Transformer å±‚
        self.encoder = nn.ModuleList([
            YICABERTLayer(hidden_size, num_heads) for _ in range(num_layers)
        ])
        
        # åˆ†ç±»å¤´
        self.pooler = nn.Linear(hidden_size, hidden_size)
        self.classifier = nn.Linear(hidden_size, 2)  # äºŒåˆ†ç±»ç¤ºä¾‹
        
        logger.info(f"åˆ›å»º YICA BERT æ¨¡å‹: {num_layers} å±‚, {hidden_size} ç»´")
    
    def forward(self, input_ids, attention_mask=None, token_type_ids=None):
        batch_size, seq_len = input_ids.shape
        
        # ä½ç½®ç¼–ç 
        position_ids = torch.arange(seq_len, dtype=torch.long, device=input_ids.device)
        position_ids = position_ids.unsqueeze(0).expand(batch_size, -1)
        
        if token_type_ids is None:
            token_type_ids = torch.zeros_like(input_ids)
        
        # åµŒå…¥
        word_embeds = self.embeddings['word_embeddings'](input_ids)
        pos_embeds = self.embeddings['position_embeddings'](position_ids)
        token_type_embeds = self.embeddings['token_type_embeddings'](token_type_ids)
        
        embeddings = word_embeds + pos_embeds + token_type_embeds
        embeddings = self.embeddings['LayerNorm'](embeddings)
        embeddings = self.embeddings['dropout'](embeddings)
        
        # ç¼–ç å™¨å±‚
        hidden_states = embeddings
        for layer in self.encoder:
            hidden_states = layer(hidden_states, attention_mask)
        
        # æ± åŒ–å’Œåˆ†ç±»
        pooled_output = torch.tanh(self.pooler(hidden_states[:, 0]))
        logits = self.classifier(pooled_output)
        
        return logits

class YICABERTLayer(nn.Module):
    """YICA ä¼˜åŒ–çš„ BERT å±‚"""
    
    def __init__(self, hidden_size, num_heads):
        super().__init__()
        self.attention = YICAMultiHeadAttention(hidden_size, num_heads)
        self.intermediate = nn.Linear(hidden_size, hidden_size * 4)
        self.output = nn.Linear(hidden_size * 4, hidden_size)
        self.layernorm1 = nn.LayerNorm(hidden_size)
        self.layernorm2 = nn.LayerNorm(hidden_size)
        self.dropout = nn.Dropout(0.1)
    
    def forward(self, hidden_states, attention_mask=None):
        # Self-attention
        attn_output = self.attention(hidden_states, attention_mask)
        attn_output = self.dropout(attn_output)
        hidden_states = self.layernorm1(hidden_states + attn_output)
        
        # Feed-forward
        intermediate_output = F.gelu(self.intermediate(hidden_states))
        layer_output = self.output(intermediate_output)
        layer_output = self.dropout(layer_output)
        hidden_states = self.layernorm2(hidden_states + layer_output)
        
        return hidden_states

class YICAResNetDemo(nn.Module):
    """YICA ä¼˜åŒ–çš„ç®€åŒ– ResNet æ¨¡å‹æ¼”ç¤º"""
    
    def __init__(self, num_classes=1000):
        super().__init__()
        
        # åˆå§‹å·ç§¯å±‚
        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn1 = nn.BatchNorm2d(64)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        
        # ResNet å—
        self.layer1 = self._make_layer(64, 64, 2)
        self.layer2 = self._make_layer(64, 128, 2, stride=2)
        self.layer3 = self._make_layer(128, 256, 2, stride=2)
        self.layer4 = self._make_layer(256, 512, 2, stride=2)
        
        # å…¨å±€å¹³å‡æ± åŒ–å’Œåˆ†ç±»å™¨
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = nn.Linear(512, num_classes)
        
        logger.info(f"åˆ›å»º YICA ResNet æ¨¡å‹")
    
    def _make_layer(self, in_channels, out_channels, blocks, stride=1):
        layers = []
        layers.append(YICAResNetBlock(in_channels, out_channels, stride))
        for _ in range(1, blocks):
            layers.append(YICAResNetBlock(out_channels, out_channels))
        return nn.Sequential(*layers)
    
    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)
        
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)
        
        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        x = self.fc(x)
        
        return x

class YICAResNetBlock(nn.Module):
    """YICA ä¼˜åŒ–çš„ ResNet å—"""
    
    def __init__(self, in_channels, out_channels, stride=1):
        super().__init__()
        
        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, 
                              stride=stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, 
                              stride=1, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU(inplace=True)
        
        self.shortcut = nn.Sequential()
        if stride != 1 or in_channels != out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels, out_channels, kernel_size=1, 
                         stride=stride, bias=False),
                nn.BatchNorm2d(out_channels)
            )
    
    def forward(self, x):
        residual = self.shortcut(x)
        
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)
        
        out = self.conv2(out)
        out = self.bn2(out)
        
        out += residual
        out = self.relu(out)
        
        return out

class YICABenchmarkSuite:
    """YICA åŸºå‡†æµ‹è¯•å¥—ä»¶"""
    
    def __init__(self):
        self.results = []
        self.models = {}
        
    def register_model(self, name: str, model: nn.Module, input_shape: Tuple):
        """æ³¨å†Œæ¨¡å‹"""
        self.models[name] = {
            'model': model,
            'input_shape': input_shape
        }
        logger.info(f"æ³¨å†Œæ¨¡å‹: {name}, è¾“å…¥å½¢çŠ¶: {input_shape}")
    
    def benchmark_model(self, model_name: str, batch_sizes: List[int] = [1, 4, 8, 16]) -> List[BenchmarkResult]:
        """åŸºå‡†æµ‹è¯•å•ä¸ªæ¨¡å‹"""
        if model_name not in self.models:
            raise ValueError(f"æ¨¡å‹ {model_name} æœªæ³¨å†Œ")
        
        model_info = self.models[model_name]
        model = model_info['model']
        base_input_shape = model_info['input_shape']
        
        results = []
        
        logger.info(f"ğŸš€ å¼€å§‹åŸºå‡†æµ‹è¯•æ¨¡å‹: {model_name}")
        
        for batch_size in batch_sizes:
            logger.info(f"  æµ‹è¯•æ‰¹å¤§å°: {batch_size}")
            
            # åˆ›å»ºè¾“å…¥æ•°æ®
            input_shape = (batch_size,) + base_input_shape[1:]
            
            if model_name.startswith('llama') or model_name.startswith('bert'):
                # æ–‡æœ¬æ¨¡å‹
                inputs = torch.randint(0, 1000, input_shape, dtype=torch.long)
                seq_len = input_shape[1]
            else:
                # å›¾åƒæ¨¡å‹
                inputs = torch.randn(input_shape)
                seq_len = None
            
            # é¢„çƒ­
            model.eval()
            with torch.no_grad():
                for _ in range(3):
                    _ = model(inputs)
            
            # åŸºå‡†æµ‹è¯•
            start_time = time.time()
            num_runs = 10
            
            with torch.no_grad():
                for _ in range(num_runs):
                    output = model(inputs)
            
            end_time = time.time()
            
            # è®¡ç®—æŒ‡æ ‡
            total_time = end_time - start_time
            avg_latency_ms = (total_time / num_runs) * 1000
            
            if seq_len:
                total_tokens = batch_size * seq_len * num_runs
                throughput = total_tokens / total_time
            else:
                throughput = batch_size * num_runs / total_time
            
            # å†…å­˜ä½¿ç”¨ï¼ˆæ¨¡æ‹Ÿï¼‰
            memory_usage_mb = self._estimate_memory_usage(model, input_shape)
            
            result = BenchmarkResult(
                model_name=model_name,
                batch_size=batch_size,
                sequence_length=seq_len or input_shape[-1],
                latency_ms=avg_latency_ms,
                throughput_tokens_per_sec=throughput,
                memory_usage_mb=memory_usage_mb,
                peak_memory_mb=memory_usage_mb * 1.2
            )
            
            results.append(result)
            self.results.append(result)
            
            logger.info(f"    å»¶è¿Ÿ: {avg_latency_ms:.2f}ms")
            logger.info(f"    ååé‡: {throughput:.2f} tokens/sec")
            logger.info(f"    å†…å­˜ä½¿ç”¨: {memory_usage_mb:.2f}MB")
        
        return results
    
    def _estimate_memory_usage(self, model: nn.Module, input_shape: Tuple) -> float:
        """ä¼°ç®—å†…å­˜ä½¿ç”¨é‡"""
        # ç®€å•çš„å†…å­˜ä¼°ç®—
        param_memory = sum(p.numel() * 4 for p in model.parameters()) / 1024 / 1024  # MB
        input_memory = np.prod(input_shape) * 4 / 1024 / 1024  # MB
        activation_memory = param_memory * 0.5  # ä¼°ç®—æ¿€æ´»å†…å­˜
        
        return param_memory + input_memory + activation_memory
    
    def benchmark_all(self) -> Dict[str, List[BenchmarkResult]]:
        """åŸºå‡†æµ‹è¯•æ‰€æœ‰æ¨¡å‹"""
        all_results = {}
        
        for model_name in self.models.keys():
            try:
                results = self.benchmark_model(model_name)
                all_results[model_name] = results
            except Exception as e:
                logger.error(f"æ¨¡å‹ {model_name} åŸºå‡†æµ‹è¯•å¤±è´¥: {e}")
        
        return all_results
    
    def generate_report(self, output_dir: str = "./yica_benchmark_results"):
        """ç”ŸæˆåŸºå‡†æµ‹è¯•æŠ¥å‘Š"""
        os.makedirs(output_dir, exist_ok=True)
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        results_data = []
        for result in self.results:
            results_data.append({
                'model_name': result.model_name,
                'batch_size': result.batch_size,
                'sequence_length': result.sequence_length,
                'latency_ms': result.latency_ms,
                'throughput_tokens_per_sec': result.throughput_tokens_per_sec,
                'memory_usage_mb': result.memory_usage_mb,
                'peak_memory_mb': result.peak_memory_mb
            })
        
        with open(os.path.join(output_dir, 'benchmark_results.json'), 'w') as f:
            json.dump(results_data, f, indent=2)
        
        # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
        self._create_performance_charts(output_dir)
        
        # ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Š
        self._create_text_report(output_dir)
        
        logger.info(f"åŸºå‡†æµ‹è¯•æŠ¥å‘Šå·²ç”Ÿæˆ: {output_dir}")
    
    def _create_performance_charts(self, output_dir: str):
        """åˆ›å»ºæ€§èƒ½å›¾è¡¨"""
        try:
            import matplotlib.pyplot as plt
            import seaborn as sns
            
            # è®¾ç½®æ ·å¼
            plt.style.use('seaborn-v0_8')
            sns.set_palette("husl")
            
            # å»¶è¿Ÿå¯¹æ¯”å›¾
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
            
            # æŒ‰æ¨¡å‹åˆ†ç»„
            models = {}
            for result in self.results:
                if result.model_name not in models:
                    models[result.model_name] = []
                models[result.model_name].append(result)
            
            # å»¶è¿Ÿå›¾
            for model_name, results in models.items():
                batch_sizes = [r.batch_size for r in results]
                latencies = [r.latency_ms for r in results]
                ax1.plot(batch_sizes, latencies, marker='o', label=model_name)
            
            ax1.set_xlabel('æ‰¹å¤§å°')
            ax1.set_ylabel('å»¶è¿Ÿ (ms)')
            ax1.set_title('YICA æ¨¡å‹å»¶è¿Ÿå¯¹æ¯”')
            ax1.legend()
            ax1.grid(True)
            
            # ååé‡å›¾
            for model_name, results in models.items():
                batch_sizes = [r.batch_size for r in results]
                throughputs = [r.throughput_tokens_per_sec for r in results]
                ax2.plot(batch_sizes, throughputs, marker='s', label=model_name)
            
            ax2.set_xlabel('æ‰¹å¤§å°')
            ax2.set_ylabel('ååé‡ (tokens/sec)')
            ax2.set_title('YICA æ¨¡å‹ååé‡å¯¹æ¯”')
            ax2.legend()
            ax2.grid(True)
            
            plt.tight_layout()
            plt.savefig(os.path.join(output_dir, 'performance_comparison.png'), dpi=300)
            plt.close()
            
            # å†…å­˜ä½¿ç”¨å›¾
            fig, ax = plt.subplots(figsize=(10, 6))
            
            for model_name, results in models.items():
                batch_sizes = [r.batch_size for r in results]
                memory_usage = [r.memory_usage_mb for r in results]
                ax.bar([f"{model_name}\nBS{bs}" for bs in batch_sizes], 
                      memory_usage, alpha=0.7, label=model_name)
            
            ax.set_ylabel('å†…å­˜ä½¿ç”¨ (MB)')
            ax.set_title('YICA æ¨¡å‹å†…å­˜ä½¿ç”¨å¯¹æ¯”')
            ax.tick_params(axis='x', rotation=45)
            plt.tight_layout()
            plt.savefig(os.path.join(output_dir, 'memory_usage.png'), dpi=300)
            plt.close()
            
        except ImportError:
            logger.warning("matplotlib æˆ– seaborn æœªå®‰è£…ï¼Œè·³è¿‡å›¾è¡¨ç”Ÿæˆ")
    
    def _create_text_report(self, output_dir: str):
        """åˆ›å»ºæ–‡æœ¬æŠ¥å‘Š"""
        report_path = os.path.join(output_dir, 'benchmark_report.md')
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# YICA-Mirage åŸºå‡†æµ‹è¯•æŠ¥å‘Š\n\n")
            f.write(f"ç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            # æŒ‰æ¨¡å‹åˆ†ç»„ç»Ÿè®¡
            models = {}
            for result in self.results:
                if result.model_name not in models:
                    models[result.model_name] = []
                models[result.model_name].append(result)
            
            for model_name, results in models.items():
                f.write(f"## {model_name.upper()} æ¨¡å‹æ€§èƒ½\n\n")
                f.write("| æ‰¹å¤§å° | å»¶è¿Ÿ (ms) | ååé‡ (tokens/s) | å†…å­˜ä½¿ç”¨ (MB) |\n")
                f.write("|--------|-----------|-------------------|---------------|\n")
                
                for result in results:
                    f.write(f"| {result.batch_size} | {result.latency_ms:.2f} | "
                           f"{result.throughput_tokens_per_sec:.2f} | {result.memory_usage_mb:.2f} |\n")
                
                f.write("\n")
            
            # æ€§èƒ½æ€»ç»“
            f.write("## æ€§èƒ½æ€»ç»“\n\n")
            f.write("### å…³é”®æŒ‡æ ‡\n\n")
            
            best_latency = min(self.results, key=lambda x: x.latency_ms)
            best_throughput = max(self.results, key=lambda x: x.throughput_tokens_per_sec)
            lowest_memory = min(self.results, key=lambda x: x.memory_usage_mb)
            
            f.write(f"- **æœ€ä½å»¶è¿Ÿ**: {best_latency.model_name} (BS{best_latency.batch_size}): {best_latency.latency_ms:.2f}ms\n")
            f.write(f"- **æœ€é«˜ååé‡**: {best_throughput.model_name} (BS{best_throughput.batch_size}): {best_throughput.throughput_tokens_per_sec:.2f} tokens/s\n")
            f.write(f"- **æœ€ä½å†…å­˜**: {lowest_memory.model_name} (BS{lowest_memory.batch_size}): {lowest_memory.memory_usage_mb:.2f}MB\n\n")
            
            f.write("### YICA ä¼˜åŒ–æ•ˆæœ\n\n")
            f.write("- **CIM é˜µåˆ—åŠ é€Ÿ**: çŸ©é˜µä¹˜æ³•è¿ç®—é€šè¿‡ CIM å†…å­˜å†…è®¡ç®—æ˜¾è‘—åŠ é€Ÿ\n")
            f.write("- **SPM ä¼˜åŒ–**: æ™ºèƒ½æ•°æ®å±€éƒ¨æ€§ç®¡ç†å‡å°‘ DRAM è®¿é—®å¼€é”€\n")
            f.write("- **ç®—å­èåˆ**: å‡å°‘ä¸­é—´ç»“æœå­˜å‚¨ï¼Œæå‡ç«¯åˆ°ç«¯æ€§èƒ½\n")
            f.write("- **æŒ‡ä»¤çº§ä¼˜åŒ–**: YIS æŒ‡ä»¤é›†é’ˆå¯¹ AI è®¡ç®—æ¨¡å¼ä¼˜åŒ–\n\n")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='YICA-Mirage ç«¯åˆ°ç«¯æ¼”ç¤º')
    parser.add_argument('--model', choices=['llama', 'bert', 'resnet', 'all'], 
                       default='all', help='è¦æµ‹è¯•çš„æ¨¡å‹')
    parser.add_argument('--batch-sizes', nargs='+', type=int, default=[1, 4, 8, 16],
                       help='æµ‹è¯•çš„æ‰¹å¤§å°')
    parser.add_argument('--output-dir', default='./yica_demo_results',
                       help='ç»“æœè¾“å‡ºç›®å½•')
    parser.add_argument('--quick', action='store_true',
                       help='å¿«é€Ÿæµ‹è¯•æ¨¡å¼ï¼ˆå‡å°‘æµ‹è¯•æ¬¡æ•°ï¼‰')
    
    args = parser.parse_args()
    
    logger.info("ğŸš€ å¯åŠ¨ YICA-Mirage ç«¯åˆ°ç«¯æ¼”ç¤º")
    
    # åˆ›å»ºåŸºå‡†æµ‹è¯•å¥—ä»¶
    benchmark = YICABenchmarkSuite()
    
    # æ³¨å†Œæ¨¡å‹
    if args.model in ['llama', 'all']:
        llama_model = YICALlamaDemo(vocab_size=32000, hidden_size=512, num_layers=6)
        benchmark.register_model('llama', llama_model, (1, 128))  # (batch, seq_len)
    
    if args.model in ['bert', 'all']:
        bert_model = YICABERTDemo(vocab_size=30522, hidden_size=768, num_layers=12)
        benchmark.register_model('bert', bert_model, (1, 128))  # (batch, seq_len)
    
    if args.model in ['resnet', 'all']:
        resnet_model = YICAResNetDemo(num_classes=1000)
        benchmark.register_model('resnet', resnet_model, (1, 3, 224, 224))  # (batch, channels, height, width)
    
    # è¿è¡ŒåŸºå‡†æµ‹è¯•
    if args.quick:
        batch_sizes = [1, 8]
    else:
        batch_sizes = args.batch_sizes
    
    try:
        if args.model == 'all':
            results = benchmark.benchmark_all()
        else:
            results = {args.model: benchmark.benchmark_model(args.model, batch_sizes)}
        
        # ç”ŸæˆæŠ¥å‘Š
        benchmark.generate_report(args.output_dir)
        
        logger.info("ğŸ‰ YICA-Mirage ç«¯åˆ°ç«¯æ¼”ç¤ºå®Œæˆ!")
        logger.info(f"ğŸ“Š è¯¦ç»†ç»“æœè¯·æŸ¥çœ‹: {args.output_dir}")
        
    except Exception as e:
        logger.error(f"âŒ æ¼”ç¤ºè¿è¡Œå¤±è´¥: {e}")
        return 1
    
    return 0

if __name__ == '__main__':
    exit(main()) 